<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Bowen He&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Bowen He&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Bowen He&#39;s Blog">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Bowen He&#39;s Blog">
  
    <link rel="alternate" href="/atom.xml" title="Bowen He&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Bowen He&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">劝君惜取少年时.</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-policy_gradient" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/11/25/policy_gradient/" class="article-date">
  <time datetime="2019-11-25T14:50:00.000Z" itemprop="datePublished">2019-11-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/11/25/policy_gradient/">Policy Gradient关键点分析</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>导读：强化学习入门，先依次学习了q-learning，DQN，Dueling DQN；</p>
<p>​           近日在知乎浏览，发现openai更偏爱policy gradient，知乎大佬讲解说，是因为policy gradient相比dqn所需数据更少。使用较少训练数据而得到较好的结果，恰恰能减少线上成本，因此希望能理清楚为什么policy gradient能使用更少的训练数据？其与dqn的区别在哪里。</p>
<h2 id="与DQN的区别"><a href="#与DQN的区别" class="headerlink" title="与DQN的区别"></a>与DQN的区别</h2><p>我们知道，在DQN中，我们将state经过nn网络产生Q值，根据Q值大小来选取action，而policy gradient则是将state经过nn网络直接产生采取每个action的概率，直接选取action。可是该如何判断</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/11/25/policy_gradient/" data-id="ck3fyr2ej000juclvebhax9i7" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/强化学习/">强化学习</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Dueling DQN" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/11/05/Dueling DQN/" class="article-date">
  <time datetime="2019-11-05T14:50:00.000Z" itemprop="datePublished">2019-11-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/11/05/Dueling DQN/">Dueling Network Architecture for Deep Reinforcement Learning 论文精读</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>导读</p>
<p>本文主要对论文Dueling DQN <a href="https://arxiv.org/pdf/1511.06581.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1511.06581.pdf</a> 提出的背景知识，解决的问题，带来的优势及其原因进行一些解读和分享。</p>
<h2 id="从Q-Learning到DQN"><a href="#从Q-Learning到DQN" class="headerlink" title="从Q-Learning到DQN"></a>从Q-Learning到DQN</h2><p>强化学习入门先学习了Q-Learning，因为states可能有千千万万，对应states*action个q-value值，随着states的增加，会有内存不够的问题。怎么办？DQN(Deep Q Network)出现了，其原理就是将state&amp;action共同作为输入，所有action对应的q-value作为输出，将q-value函数的模拟，由DQN网络参数来替代。DQN的原理不再赘述，简单回顾一下数学公式：</p>
<p>$L<em>{i}(\theta</em>{i})=E<em>{s,a,r,s’}[(y</em>{i}^{QDN}-Q(s,a;\theta_{i}))^{2}]$</p>
<p>$y<em>{i}^{DQN}=r+\gamma max</em>{a} Q(s’,a’;\theta^{-})$</p>
<p>在这里我们依然可以用q-learning的方法去估计 $\theta$ ，但是实际这样做表现比较差（为什么？文章没说）。</p>
<p>后来有人提出，可以将q-target网络参数固定几轮，与此同时更新q-eval。采用这种方法，可以极大提高算法的稳定性。这种方法是属于off-policy的，因为其选择action的时候，是根据线下的greedy policy，而不是根据线上实时学到的policy。</p>
<p>另外一个DQN很重要的方法，是experience replay。也就是说DQN网络不仅仅记住当前的state，它还会记忆之前的state，存到memory，每次更新的时候，随机从memory里选取一些state，也就是random sample一个mini-batch的states出来。experience replay通过重复利用数据，增加了数据的有效性，又因为每次随机从记忆池抽样，可以减少每次更新所用样本的方差。</p>
<h2 id="从DQN到Double-DQN"><a href="#从DQN到Double-DQN" class="headerlink" title="从DQN到Double DQN"></a>从DQN到Double DQN</h2>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/11/05/Dueling DQN/" data-id="ck3fyr2e10005uclvs1h9xvyn" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/强化学习/">强化学习</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Recsys-Spotify-2018-Challenge" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/15/Recsys-Spotify-2018-Challenge/" class="article-date">
  <time datetime="2018-07-15T14:20:00.000Z" itemprop="datePublished">2018-07-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/15/Recsys-Spotify-2018-Challenge/">Recsys-Spotify-2018-Challenge比赛总结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>ACM（国际计算机学会）主办的推荐系统专场（Recsys）是推荐系统圈子的顶级会议，2018年ACM和spotify联合举办的Recsys challenge，本次比赛一共分为两个track，main track，只能用比赛方提供的数据，creative track，除了比赛方提供的数据还可以用外部数据。我和队友们在本次比赛的main track中，取得public board第六名的成绩，整个比赛，感谢我的老板兼队友提供的很多很好的idea，也让我对数据挖掘有了很多新的思考，这条路我还需要很多持之以恒的努力。</p>
<p><a href="http://www.recsyschallenge.com/2018/" target="_blank" rel="external">http://www.recsyschallenge.com/2018/</a></p>
<h2 id="赛题描述"><a href="#赛题描述" class="headerlink" title="赛题描述"></a>赛题描述</h2><h3 id="数据描述"><a href="#数据描述" class="headerlink" title="数据描述"></a>数据描述</h3><p>本次比赛由ACM Recsys和Spotify联合举办的recsys challenge，赛题给定了一百万的歌单数据集，版权由spotify所有，本文之后将简称该数据集为MSD，具体数据详情见以下：</p>
<p>每个歌单metadata包括</p>
<p>playlist_duration,  歌单整体时长</p>
<p>playlist_title, 歌单名称</p>
<p>track_num, 歌单的单曲数量</p>
<p>last_modified_time, 最后一次修改歌单的时间</p>
<p>track, 每首单曲</p>
<p> each track’s position in the playlist, 每首单曲在歌单中的位置</p>
<p>每首单曲的metadata包括</p>
<p>track_name,  单曲歌名</p>
<p>track_duration, 单曲时长</p>
<p>artist, 单曲歌手</p>
<p>album, 单曲所属专辑</p>
<h3 id="任务描述"><a href="#任务描述" class="headerlink" title="任务描述"></a>任务描述</h3><p>比赛的大目标，即是自动延续歌单，给定一个歌单，歌单已经含有1-250首歌不等，要求预测出500首更高概率会出现在歌单里的单曲，按概率从高到低提交，这个任务在研究领域有个专业名称，playlist auto continuation,  本次比赛分为十个子任务：</p>
<ol>
<li>只给定歌单名，预测500首单曲；</li>
<li>给定歌单名，给定最top的1首歌，预测500首单曲；</li>
<li>给定歌单名，给定按顺序出现的最top的5首歌，预测500首单曲；</li>
<li>不给歌单名，给定按顺序出现的最top的5首歌，预测500首单曲；</li>
<li>给定歌单名，给定按顺序出现的最top的10首歌，预测500首单曲；</li>
<li>不给歌单名，给定按顺序出现的最top的10首歌，预测500首单曲；</li>
<li>给定按顺序出现的最top的25首歌，预测500首单曲；</li>
<li>给定歌单随机位置的25首歌，预测500首单曲；</li>
<li>给定按顺序出现的最top的100首歌，预测500首单曲；</li>
<li>给定歌单随机位置的100首歌，预测500首单曲。</li>
</ol>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>因为此次比赛属于推荐性质的问题，大方法上，我们采用的是based-on item collaborative filtering, 针对赛题里十个子任务各自的特性，我们将十个子任务按其数据特性，分为4种case，对原有cf算法作了4个不同的改进。也是这次比赛，更让我体会到这类推荐任务，甚至数据挖掘想做好的前提，就是要深刻理解数据，根据数据的特性，来采用有效的方法，想起上周同一个比赛，老板eda发现的magic feature，提升了3个百分点，扯远了…</p>
<h3 id="Based-On-Item-Collaborative-Filtering"><a href="#Based-On-Item-Collaborative-Filtering" class="headerlink" title="Based-On Item Collaborative Filtering"></a>Based-On Item Collaborative Filtering</h3><p>这个算法不作过多介绍，推荐算法老牌战斗机，简单概述就是，如果很多user喜欢item A, B, C，那么对于喜欢itemA, B的user，我给他也推荐C，简单的逻辑，好用的算法；</p>
<p>优点：相比based-on user collaborative filtering, based-on item计算更加efficency，因为绝大数多场景，user的数量总是远远过于item的，另外因为user的偏好往往更多元，举个例子，一个人喜欢听周杰伦的‘告白气球’，他也可能喜欢听钢琴曲‘土耳其进行曲’，这是很常见的，可是这两首歌在同一歌单出现的概率，应该不太大，同一歌单中的单曲，应该总有某个部分的相似性，促使它们被放在同一歌单。</p>
<p>缺点：协同过滤的算法，往往会更倾向推荐热门的歌单，使得一些小众的歌得不到重视。</p>
<h3 id="Task1-Subtask-2-3-4-5-6"><a href="#Task1-Subtask-2-3-4-5-6" class="headerlink" title="Task1-Subtask 2,3,4,5,6"></a>Task1-Subtask 2,3,4,5,6</h3><p>上面提到，我们根据不同子任务的数据特性，将2，3，4，5，6这五种子任务，归为同一种任务，按同一算法来推荐；所用的主要方法就是based on item collaborative filtering, 这个方法几乎用在了除子任务1以外的每个子任务：</p>
<p>先根据提供的MSD data构建一个大的item-user矩阵，MSD data中共有100万个歌单，和2262292首distinct的单曲，歌单即是user，单曲即是item，那么这里把所有原始数据构造成了一个大的[2262292, 1000000]的矩阵，本文以后将简称这个矩阵为大矩阵， 注意，就像绝大多数推荐系统的item-user矩阵一样，这个大矩阵有很强的稀疏性，如果初始化用一个稠密矩阵去做，很可能内存就爆了，我们采用了稀疏矩阵的办法，极大的节省了内存</p>
<p>`</p>
<pre><code>import scipy.sparse as sp

mat = sp.dok_matrix((2262292, 1000000), dtype=np.float32)

for song, pids in dic.items():

​    for pid in pids:

​        mat[song, pid] = 1

mat = mat.tocsr().sorted_indices()
</code></pre><p>`</p>
<p>假定歌单中有[A, B, C, D, E]五首歌，先计算A和所有歌曲（2262292）每首歌的相似度，这里的相似度就是依赖A和每首歌曲的共同歌单的数量，对于A和任一单曲，song1，假设只有单曲A出现在歌单list1, list2, list3，song1出现在歌单list3， list4，那么A和song1共同歌单的数量就是1，对song1的打分就是1，依次用A去对2262292每首歌计算共同歌曲分数；再用B去对2262292每首歌计算共同歌曲分数，接着C, D, E，把每首歌的5个结果求平均，再按每首歌得分从高到低排列，选取除掉已出现在歌单中的[A, B, C, D, E]五首歌，剩下的top500，即为我们的推荐歌单；</p>
<p>但这里的问题是，仅仅用共同歌单数，会导致那些热门歌曲，出现在很多歌单的歌，有更高的概率被推荐，这个时候热门的因素会胜过相似的因素，怎么办？很自然可以想到，我们可以用共同歌单数量，除以每首歌各自出现的歌单数量；这样不就可以平衡热门单曲的因素了吗。</p>
<p>在这个思路上，我们参考了这位大佬的论文：</p>
<p><a href="http://www.ke.tu-darmstadt.de/events/PL-12/papers/08-aiolli.pdf" target="_blank" rel="external">http://www.ke.tu-darmstadt.de/events/PL-12/papers/08-aiolli.pdf</a></p>
<p>大佬在论文提出了一个创新的公式，简单概括，这个公式的分母除以了这首歌和被推荐的歌的出现频率的n次方的积；这样可以很好的平衡掉热门歌曲的因素，使得一些小众歌也可以被“平等对待”；</p>
<p>大佬的源码也给出来了，给了我们很好的参考，我们在此基础上作了修改和一些优化，因为我们的数据集更大，同时很稀疏，我们采用了稀疏矩阵方式进行计算，极大的提高了计算速度。</p>
<h3 id="Task2-Subtask-7-9"><a href="#Task2-Subtask-7-9" class="headerlink" title="Task2-Subtask 7,9"></a>Task2-Subtask 7,9</h3><p>这两个子任务都是给定一个歌单的前n首歌，来预测推荐的500首歌。相比之前只给1首歌，5首歌，10首歌，这里的25首歌和100首歌会有一定的序列特征，这个比赛最有意思的地方，就是同一大任务下小任务各自的数据特性，深入挖掘数据特性，应数据制宜，才是提高推荐效果的关键。怎么利用这里的序列特性？之前在Task1中采用的算法，歌单的每首歌都被同等对待了，所有歌曲中一首歌和这整个歌单的相似度，由这首歌和歌单每首歌相似度的平均值来计算；但这里，我们对在靠近尾部的歌，其计算的相似度给了更高的权重，之前是简单的average, 加权重以后变成了weighted average.</p>
<h3 id="Task3-Subtask-8-10"><a href="#Task3-Subtask-8-10" class="headerlink" title="Task3-Subtask 8, 10"></a>Task3-Subtask 8, 10</h3><p>这两个子任务是给定一个歌单随机位置的n首歌，来预测推荐的500首歌。我们在基本算法的基础上，应用上了SLIM。</p>
<h3 id="Task4-Subtask-1"><a href="#Task4-Subtask-1" class="headerlink" title="Task4-Subtask 1"></a>Task4-Subtask 1</h3><p> 之所以把子任务1放到最后来写，是因为这里有很有意思的创新，分享出来希望也能帮到大家。我们以上的基本算法是根据单曲-歌单的共现关系计算相似度进而推荐，但子任务1只给定了歌单名，除此之外没有过多的信息。我们想到，歌单的名字在一定程度上和歌单里的单曲是有很大的关系的，比如一个歌单叫”爱的进行时“，那很大程度，它含有大量的爱情相关的单曲，比如”告白气球“，比如”你问我爱你有多深“，等等；这个时候另一个歌单叫”爱的故事“，那这两个歌单在单曲上应该会有相当大的一部分交集，也就是说，歌单的词-单曲的共现关系也是可以用起来的！延续基本算法，我们构建了词-单曲的稀疏矩阵，作了类似cf的算法，来说说实现细节：</p>
<p>（1）首先是这些歌单名作了一些简单的自然语言处理，pipeline如下：</p>
<p>lower words -&gt; remove repetition characters -&gt; remove special characters</p>
<p>先小写所有字母，去除一个单词中连续重复出现2次以上的字母，只保留一个，最后去掉一些字母以外的特殊符号，这里因为都是英文所以不需要分词处理，source code也给出来了，参考着一个kaggle大佬的kernel写的</p>
<p><a href="https://github.com/LauraBowenHe/Recsys-Spotify-2018-challenge/blob/master/src/utilities/title_preprocess.py#L7" target="_blank" rel="external">https://github.com/LauraBowenHe/Recsys-Spotify-2018-challenge/blob/master/src/utilities/title_preprocess.py#L7</a></p>
<p>（2）我们在第一步处理完，可以得到clean title，这个时候，根据所有单词的unique数量，和所有单曲的数量，做一个 词-单曲的稀疏矩阵，矩阵shape是[词数量，单曲数量2262292]，假设歌单名叫’party’，把’party’这个词那一行，对应的该歌单所有出现的单曲的位置+1，当另一个歌单叫’party dance’，我们把’party’和‘dance‘对应的两行，对应的该歌单所有出现的单曲的位置+1，这样在最终预测时，比如歌单名叫’happy party’, 我们找到’happy’和’party’对应的那两行，[2, 2262292]的相似度小矩阵，求平均，得到[1,2262292]的相似度矩阵，然后和之前一样，按概率从高到低选取top500。</p>
<h2 id="一些赛后想到的idea"><a href="#一些赛后想到的idea" class="headerlink" title="一些赛后想到的idea"></a>一些赛后想到的idea</h2><p>赛后感觉还是有很多可以提高的方法：</p>
<p>task 4中自然语言处理的那部分可以做得再细一点，比如去掉停用词；比如词性stemmerazation和lemmatization，这个在nltk都是有现成的python包的，可以直接调用；</p>
<p>再比如歌单名找词的时候，遇到没有对应词的情况，我直接返回了随机的500首，其实可以用一些fasttext预训练的word embedding, 找出现在矩阵中词集合最相似的近义词；</p>
<p>有一点遗憾，可能加上这些方法，应该会取得更好的名次，但学习的路漫漫，持之以恒才是王道呀。</p>
<h2 id="一些不大成功的尝试"><a href="#一些不大成功的尝试" class="headerlink" title="一些不大成功的尝试"></a>一些不大成功的尝试</h2><h3 id="word2vec"><a href="#word2vec" class="headerlink" title="word2vec"></a>word2vec</h3><p>word2vec其实本质用得也是单曲间共现的关系；类似文本，我们把每个歌单当作一个document，把每首歌当做一个单词，扔到gensim word2vec模型去训练，然后找和歌单中出现的单曲集合最相似的不包含歌单单曲的500首单曲，gensim把代码封装的很好，直接将这个集合丢进去就可以了，不需要每首歌依次计算求平均，这里的代码也分享出来吧</p>
<p>训练的：</p>
<p><a href="https://github.com/LauraBowenHe/Recsys-Spotify-2018-challenge/blob/master/try/word2vec.py" target="_blank" rel="external">https://github.com/LauraBowenHe/Recsys-Spotify-2018-challenge/blob/master/try/word2vec.py</a></p>
<p>预测的：</p>
<p><a href="https://github.com/LauraBowenHe/Recsys-Spotify-2018-challenge/blob/master/try/prediction_v12.py" target="_blank" rel="external">https://github.com/LauraBowenHe/Recsys-Spotify-2018-challenge/blob/master/try/prediction_v12.py</a></p>
<p>但效果并没有协同过滤好，印象中r-precision相差3～4个百分点。</p>
<h3 id="ensemble-cf"><a href="#ensemble-cf" class="headerlink" title="ensemble cf"></a>ensemble cf</h3><p>我们想到，既然能用单曲-歌单的关系，那么artist-歌单的关系，album-歌单的关系，应该都能用吧，计算出来的相似度加权平均效果应该会更好，但实验结果发现，ensemble并无显示提高，有时候甚至有一点点下降，可能的原因，只利用这些例如单曲-歌单的共现关系的话，单曲中已经涵盖了artist和album的信息，很有可能再单独加入使得信息冗余，进而降低准确率。</p>
<h3 id="star-embedding"><a href="#star-embedding" class="headerlink" title="star embedding"></a>star embedding</h3><p>facebook发了一篇很牛逼的论文，大概是说embedding everything，相关代码也开源了，尝试了一下不是很会用。。时间紧迫就没有作过多的探索放弃了</p>
<h2 id="其他选手的方法"><a href="#其他选手的方法" class="headerlink" title="其他选手的方法"></a>其他选手的方法</h2><p>因为举办方要求所有参赛选手把代码开源，于是上github欣赏了一下其他参赛选手的方法，看到挺有意思的也作了简单的总结：</p>
<p>今天太累了…</p>
<p>待续…</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/15/Recsys-Spotify-2018-Challenge/" data-id="ck3fyr2dy0004uclvjdi3c9yy" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/推荐系统/">推荐系统</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Word2Vec" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/13/Word2Vec/" class="article-date">
  <time datetime="2017-11-13T15:45:00.000Z" itemprop="datePublished">2017-11-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/13/Word2Vec/">Word2Vec模型</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="Stanford-cs224n-2017-lecture2课堂笔记（1）-自己的理解"><a href="#Stanford-cs224n-2017-lecture2课堂笔记（1）-自己的理解" class="headerlink" title="Stanford cs224n 2017 lecture2课堂笔记（1）+ 自己的理解"></a>Stanford cs224n 2017 lecture2课堂笔记（1）+ 自己的理解</h3><p>Reference:</p>
<p><a href="https://web.stanford.edu/class/cs224n/lectures/cs224n-2017-lecture2.pdf" target="_blank" rel="external">https://web.stanford.edu/class/cs224n/lectures/cs224n-2017-lecture2.pdf</a></p>
<p><a href="https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/?blogsub=confirming#subscribe-blog" target="_blank" rel="external">https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/?blogsub=confirming#subscribe-blog</a></p>
<p>正式开笔前，说说废话，下定决心把Stanford这个系列的课上一遍，好好打打自然语言处理的基础，而又因为纯听课的效果对我而言比不上同时更blog做笔记来得好，因此每日多花些时间来写一写。</p>
<h3 id="Why-word2vec"><a href="#Why-word2vec" class="headerlink" title="Why word2vec?"></a>Why word2vec?</h3><p>说到用vector来表达词，一种很常见的方法是离散化的表达，比如one-hot representation, 什么one-hot representation? 假设一个大词库有N个词，想表达Xi, 那么我们就定义一个维度为N的vector，除了第i位为1，其他全为0，举个例子吧：</p>
<p>词库：I have a computer.</p>
<p>每个词的vector为如下形式：</p>
<p>I: [1, 0, 0, 0]</p>
<p>have: [0, 1, 0, 0]</p>
<p>a: [0, 0, 1, 0]</p>
<p>computer: [0, 0, 0, 1]</p>
<p>可是这样离散化表达有什么缺点呢？</p>
<ol>
<li>假设词库很大很大，那么每个词的vector就会很长，后期计算量也会很大，导致我们的模型难以训练；</li>
<li>离散化表达难以体现词和词之间的相互关系，比如一个大的词库里，频繁出现“面膜 护肤”等词，按以上的离散化表达，两个one-hot vector向量的dot multiplication(点乘)是0，难以用cosine等方式计算词和词的相似性。</li>
</ol>
<p>于是～word2vec模型上线，相对于离散化的表达(discrete representation)， word2vec模型属于分布式表达（distributional representation)，which means “distribution of weights across weight”， 也就是说，区别于长度为整个词库数量N的vector，通常用来表示每个词的vector的维数不会很大，而每个element都有一个数，例如lingusitic: [0.7, 0.3, 0.1, 0.2, 0.5]， 这个vector称为词向量，而从单词map到vector这一步，称为word embedding。可见，word2vec通过使用较小维度的vector降低了训练模型需要的space and time complexity，词向量可以通过multiplication(点乘)计算相似性。</p>
<h3 id="两个算法"><a href="#两个算法" class="headerlink" title="两个算法"></a>两个算法</h3><h5 id="Skip-grams-SG"><a href="#Skip-grams-SG" class="headerlink" title="Skip-grams(SG)"></a>Skip-grams(SG)</h5><p>这个算法，是根据给定的词预测词上下文: target -&gt; context</p>
<p>input layer是给定的词，output layer是预测的词上下文，盗了一张参考链接的图：</p>
<p>（原图地址：<a href="https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/?blogsub=confirming#subscribe-blog" target="_blank" rel="external">https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/?blogsub=confirming#subscribe-blog</a>)</p>
<p><img src="/images/word2vec-skip-gram.png" alt=""></p>
<p>在这个模型里，我们把给定的词用one-hot representation表示，vector的长度V即为词库的词数，从input layer映射到hidden layer，我们需要初始化一个W1(VxN)将one-hot转成词向量，因为one-hot的特殊性质举例：[1, 0, 0, 0]，除了特定位置为1，其他位置都为0，因此这个转换词向量的过程，仅仅需要将词向量元素=1的对应的Wmatrix那一行copy就好了，再将hidden layer层乘以W2，得到C个v维词向量，C为word context的词数，每个词向量中，对应位置对高概率的那个词，即为预测词。</p>
<h5 id="Continuous-Bag-of-Words-CBOW"><a href="#Continuous-Bag-of-Words-CBOW" class="headerlink" title="Continuous Bag of Words(CBOW)"></a>Continuous Bag of Words(CBOW)</h5><p>和skip-gram相反，CBOW根据词上下文环境(word context)来预测这个环境中缺失的那个词，举例</p>
<p>I was born in _, so my native language is Madarine. 这里很明显缺失的那个词为China, 而整个语句为word context，我们的output就是要预测的缺失的词。</p>
<p>再盗图一张，来自相同reference链接。</p>
<p><img src="/images/word2vec-cbow.png" alt=""></p>
<p>在这个模型中，input layer中输入的是给定word context中所有词(C个)的one-hot vector(V)，与weights矩阵W1(VxN)相乘，分别得到多词向量vector(N), 取平均值即为hidden layer，再由hidden layer乘以weights矩阵W2(NxV)得到output词向量v，维度为V，最高分数的那一维度对应的词就是predict word。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/13/Word2Vec/" data-id="ck3fyr2e70009uclvmjeqlb2g" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/深度学习/">深度学习</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-python_script_function" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/09/python_script_function/" class="article-date">
  <time datetime="2017-11-09T15:07:00.000Z" itemprop="datePublished">2017-11-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/09/python_script_function/">一些python function总结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>今天看一份代码的时候，有些python function不知其何用，想来写个博客把每次遇到的总结在一篇blog，可以时常看看。</p>
<h3 id="print-doc"><a href="#print-doc" class="headerlink" title="print(__doc__)"></a><code>print(__doc__)</code></h3><p>这个可以print出python file or function中注释部分，比如：</p>
<p> in module.py:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&quot;&quot;&quot;This is the module file, use for provide a function.&quot;&quot;&quot;</div><div class="line">def func(x):</div><div class="line">	return x</div><div class="line">&gt;&gt;&gt;import module</div><div class="line">&gt;&gt;&gt;print(module.__doc__)</div><div class="line">&gt;&gt;&gt;&apos;This is the module file, use for provide a function.&apos;</div></pre></td></tr></table></figure>
<h3 id="把一个list的string转成float"><a href="#把一个list的string转成float" class="headerlink" title="把一个list的string转成float"></a>把一个list的string转成float</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; nums = [&apos;1.0&apos;,&apos;2.0&apos;]</div><div class="line">&gt;&gt;&gt; float_nums = list(map(float, nums))</div></pre></td></tr></table></figure>
<h3 id="随机数Random-Module"><a href="#随机数Random-Module" class="headerlink" title="随机数Random Module"></a>随机数Random Module</h3><h5 id="均一分布（uniform）随机数"><a href="#均一分布（uniform）随机数" class="headerlink" title="均一分布（uniform）随机数"></a>均一分布（uniform）随机数</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt;random.unifrom(a, b)</div></pre></td></tr></table></figure>
<h5 id="两数范围内的随机整数"><a href="#两数范围内的随机整数" class="headerlink" title="两数范围内的随机整数"></a>两数范围内的随机整数</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; random.randint(a,b)</div></pre></td></tr></table></figure>
<h5 id="从sequence中随机选择一个element"><a href="#从sequence中随机选择一个element" class="headerlink" title="从sequence中随机选择一个element"></a>从sequence中随机选择一个element</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; nums = [&quot;blue&quot;, &quot;green&quot;]</div><div class="line">&gt;&gt;&gt; random.choice(nums)</div></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/09/python_script_function/" data-id="ck3fyr2eo000muclvz8ffljxu" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-kaggle_dog_breed_idnentification" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/04/kaggle_dog_breed_idnentification/" class="article-date">
  <time datetime="2017-11-04T08:50:00.000Z" itemprop="datePublished">2017-11-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/04/kaggle_dog_breed_idnentification/">kaggle dog breed identification基于Tensorflow迁移学习搭建图片分类器</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="基于Tensorflow的迁移学习应用-kaggle-dog-breed-identification构建新图片分类器"><a href="#基于Tensorflow的迁移学习应用-kaggle-dog-breed-identification构建新图片分类器" class="headerlink" title="基于Tensorflow的迁移学习应用 kaggle dog breed identification构建新图片分类器"></a>基于Tensorflow的迁移学习应用 kaggle dog breed identification构建新图片分类器</h3><p>本文所用数据来源于<a href="https://www.kaggle.com/c/dog-breed-identification" target="_blank" rel="external">https://www.kaggle.com/c/dog-breed-identification</a>, 将基于google tensorflow中的预训练的mobilenet模型和inception v3模型，对新dataset中10200张不同狗品种照片训练新的图片分类。</p>
<h4 id="Why-transfer-learning-here"><a href="#Why-transfer-learning-here" class="headerlink" title="Why transfer learning here?"></a>Why transfer learning here?</h4><ol>
<li>一个好的图片分类器，从scratch开始搭建，不仅构建cnn archtiecture会花费大量的时间精力，而且为了分类器的精准度，也需要大量的图片作为training data。</li>
<li>而实际应用中，针对不用需要而构建的分类器，通常只有小量的数据集，从scratch开始训练一个巨大的拥有百万甚至更多的parameters的cnn分类器很容导致过拟合，而使训练出的分类器在general set上表现不佳。</li>
<li>我们将使用的经过预训练的mobilenet模型和inception v3模型，是google基于 <a href="http://www.image-net.org/" target="_blank" rel="external">ImageNet</a> , 一个计算机视觉系统识别项目，目前世界上图像识别最大的数据库，其包含了分成了数千个类型、数百万张有标注的图像, 训练出的两个分类器模型，其Top-1 accuracy 分别达到78.0%和70.7%，inception v3会有更好的accuray，而mobilenet因为其轻量，训练速度更快。</li>
<li>针对与原数据库相似但size较小的数据集，使用transfer learning，将已根据</li>
</ol>
<h3 id="基于MobileNet的新分类器搭建"><a href="#基于MobileNet的新分类器搭建" class="headerlink" title="基于MobileNet的新分类器搭建"></a>基于MobileNet的新分类器搭建</h3><h5 id="准备阶段，get-code"><a href="#准备阶段，get-code" class="headerlink" title="准备阶段，get code"></a>准备阶段，get code</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/googlecodelabs/tensorflow-for-poets-2</div><div class="line">cd tensorflow-for-poets-2</div></pre></td></tr></table></figure>
<h5 id="准备阶段，get-dataset"><a href="#准备阶段，get-dataset" class="headerlink" title="准备阶段，get dataset"></a>准备阶段，get dataset</h5><p><a href="https://www.kaggle.com/c/dog-breed-identification" target="_blank" rel="external">https://www.kaggle.com/c/dog-breed-identification</a>, 下载training dataset, labels.csv和test dataset,</p>
<h5 id="预处理数据集"><a href="#预处理数据集" class="headerlink" title="预处理数据集"></a>预处理数据集</h5><p>我们直接下载得到的训练数据集中，只有所有的图片在同一个数据集，我们需要整理成模型需要的格式，即在同一个directory下，将每个label建一个subdirectory，将所有对应的图片放入当前subdirectory下，参考code可见:</p>
<p><a href="https://github.com/LauraBowenHe/dog-breed-identification/blob/master/MobileNet/classify_pic_to_dir.py" target="_blank" rel="external">https://github.com/LauraBowenHe/dog-breed-identification/blob/master/MobileNet/classify_pic_to_dir.py</a></p>
<h5 id="配置MobileNet"><a href="#配置MobileNet" class="headerlink" title="配置MobileNet"></a>配置MobileNet</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">IMAGE_SIZE=224</div><div class="line">ARCHITECTURE=&quot;mobilenet_1.0_$&#123;IMAGE_SIZE&#125;&quot;</div></pre></td></tr></table></figure>
<p>注意这里：</p>
<p>IMAGE_SIZE, 即image resolution配置的参数：128,160,192, or 224px。当然越高的resolution可以带来更高的accuray，同时也需要更多的训练时间。</p>
<p>相对模型size占最大largest MobileNet的比例: 1.0, 0.75, 0.50, or 0.25. 同样，所占比例越大，accuracy越高，也需要更多的训练时间。</p>
<p>在这个任务中，我们希望获得更可能高的accuray，所以采取以上配置。</p>
<h5 id="用tensorboard监控训练过程"><a href="#用tensorboard监控训练过程" class="headerlink" title="用tensorboard监控训练过程"></a>用tensorboard监控训练过程</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tensorboard --logdir tf_files/training_summaries &amp;</div></pre></td></tr></table></figure>
<p>在后台启用tensorboard，tensorboard可以用来监控训练过程，帮助我们更好判断是否过拟合等。</p>
<p>训练完成后，可以在浏览器输入</p>
<p><a href="http://localhost:6006" target="_blank" rel="external">http://localhost:6006</a> </p>
<p>or <a href="http://0.0.0.0:6006即可看到tensorboard为我们绘画的各种训练过程图像。" target="_blank" rel="external">http://0.0.0.0:6006即可看到tensorboard为我们绘画的各种训练过程图像。</a></p>
<h5 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">python -m scripts.retrain \</div><div class="line">  --bottleneck_dir=tf_files/bottlenecks \</div><div class="line">  --how_many_training_steps=3000 \</div><div class="line">  </div><div class="line">  --model_dir=tf_files/models/ \</div><div class="line">  --summaries_dir=tf_files/training_summaries/&quot;$&#123;ARCHITECTURE&#125;&quot; \</div><div class="line">  --output_graph=tf_files/retrained_graph.pb \</div><div class="line">  --output_labels=tf_files/retrained_labels.txt \</div><div class="line">  --architecture=&quot;$&#123;ARCHITECTURE&#125;&quot; \</div><div class="line">  --image_dir=tf_files/dog_photos</div></pre></td></tr></table></figure>
<p>注意：</p>
<ol>
<li><p>在这里，把我们之前预处理过的数据集，让在tf_files directory下。</p>
</li>
<li><p>optionally，我们可以添加更多的训练参数，详情可以参考</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">python -m scripts.retrain -h</div><div class="line">我加入了以下的参数</div><div class="line">--training_rate=0.001 \</div><div class="line">--train_batch_size=64 \</div></pre></td></tr></table></figure>
</li>
</ol>
<h5 id="调参"><a href="#调参" class="headerlink" title="调参"></a>调参</h5><p>调节training steps， training rate， train batch size等等。</p>
<h5 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h5><p>对于单个图片，可以用source code中的label_image.py</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">python -m scripts.label_image \</div><div class="line">    --graph=tf_files/retrained_graph.pb  \</div><div class="line">    --image=tf_files/flower_photos/daisy/21652746_cc379e0eea_m.jpg</div></pre></td></tr></table></figure>
<p>而针对这个狗品种分类器的任务，我们把从kaggle上下载的test dataset也放入tf_files directory下，修改了一下source中的label_image.py，增加新的文件generate_result.py, 对每个文件依次调用label_image.py，code可见</p>
<p><a href="https://github.com/LauraBowenHe/dog-breed-identification/blob/master/MobileNet/scripts/label_image.py" target="_blank" rel="external">https://github.com/LauraBowenHe/dog-breed-identification/blob/master/MobileNet/scripts/label_image.py</a></p>
<p><a href="https://github.com/LauraBowenHe/dog-breed-identification/tree/master/MobileNet" target="_blank" rel="external">https://github.com/LauraBowenHe/dog-breed-identification/tree/master/MobileNet</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python generate_result.py</div></pre></td></tr></table></figure>
<p>这一步预测时间会比较长，大概7-8小时，生成的文件会存在/tensorflow-poets-2/output/下，我们在训练前可先手动创建这个文件夹。</p>
<h3 id="基于inception-v3的新分类器搭建"><a href="#基于inception-v3的新分类器搭建" class="headerlink" title="基于inception v3的新分类器搭建"></a>基于inception v3的新分类器搭建</h3><p>inception v3的搭建和mobilenet很相似，只有在get code时有所不同。</p>
<h5 id="准备阶段，get-code-1"><a href="#准备阶段，get-code-1" class="headerlink" title="准备阶段，get code"></a>准备阶段，get code</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ git clone https://github.com/tensorflow/tensorflow</div><div class="line">$ cd tensorflow</div><div class="line">$ git checkout</div></pre></td></tr></table></figure>
<h5 id="准备阶段-get-dataset和预处理数据集"><a href="#准备阶段-get-dataset和预处理数据集" class="headerlink" title="准备阶段,  get dataset和预处理数据集"></a>准备阶段,  get dataset和预处理数据集</h5><p>参考以上</p>
<h5 id="训练模型-1"><a href="#训练模型-1" class="headerlink" title="训练模型"></a>训练模型</h5><p>retrain的代码在/examples/image_retraining，我们可以直接用刚刚mobilenet模型中，/tensorflow-for-poet-2/tf_files，因为我们之前已经有把数据集都放在那里了，当然即使没有也没关系，新建一个tf_files就行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">python retrain.py \</div><div class="line">  --bottleneck_dir=~/tensorflow-for-poets-2/tf_files/bottlenecks \</div><div class="line">  --how_many_training_steps=500 \</div><div class="line">  --model_dir=~/tensorflow-for-poets-2/tf_files/inception \</div><div class="line">  --summaries_dir=~/tensorflow-for-poets-2/tf_files/training_summaries/basic \</div><div class="line">  --output_graph=~/tensorflow-for-poets-2/tf_files/retrained_graph.pb \</div><div class="line">  --output_labels=~/tensorflow-for-poets-2/tf_files/retrained_labels.txt \</div><div class="line">  --image_dir=~/tensorflow-for-poets-2/tf_files/dog_photos</div></pre></td></tr></table></figure>
<p><code>python -m retrain.py -h 可以查阅可以添加的参数</code></p>
<p>附一张训练结束的图，可见当前分类器的validation accuracy是90.3%。</p>
<p><img src="/Users/bowenhe/Desktop/Screen Shot 2017-11-04 at 3.59.56 PM.png" alt="Screen Shot 2017-11-04 at 3.59.56 PM"></p>
<h5 id="调参-1"><a href="#调参-1" class="headerlink" title="调参"></a>调参</h5><p>调节training steps， training rate， train batch size等等。</p>
<h5 id="预测-1"><a href="#预测-1" class="headerlink" title="预测"></a>预测</h5><p>因为我们已将生成的模型放入tf_files。我们把从kaggle上下载的test dataset也放入tf_files directory下，创建了一份label_image_inceptionV3.py，增加新的文件generate_result_inceptionV3.py, 对每个文件依次调用label_image_inceptionV3.py，code可见</p>
<p><a href="https://github.com/LauraBowenHe/dog-breed-identification/blob/master/InceptionV3/label_image_inceptionV3.py" target="_blank" rel="external">https://github.com/LauraBowenHe/dog-breed-identification/blob/master/InceptionV3/label_image_inceptionV3.py</a></p>
<p><a href="https://github.com/LauraBowenHe/dog-breed-identification/blob/master/InceptionV3/generate_result_inceptionV3.py" target="_blank" rel="external">https://github.com/LauraBowenHe/dog-breed-identification/blob/master/InceptionV3/generate_result_inceptionV3.py</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python generate_result_inceptionV3.py</div></pre></td></tr></table></figure>
<p>这一步预测时间会比较长，比MobileNet所用的时间更长，大概在十四个小时，生成的文件会存在/tensorflow-poets-2/output/下，我们在训练前可先手动创建这个文件夹。</p>
<h5 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h5><p><a href="http://cs231n.github.io/transfer-learning/" target="_blank" rel="external">http://cs231n.github.io/transfer-learning/</a></p>
<p><a href="https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0" target="_blank" rel="external">https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0</a></p>
<p><a href="https://www.ouyangsong.com/2017/05/20/image-classification-retrained-based-on-inceptionv3/" target="_blank" rel="external">https://www.ouyangsong.com/2017/05/20/image-classification-retrained-based-on-inceptionv3/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/04/kaggle_dog_breed_idnentification/" data-id="ck3fyr2ef000euclvihbkrpx6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/深度学习/">深度学习</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-一些在爬虫中用到的python tricks" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/06/26/一些在爬虫中用到的python tricks/" class="article-date">
  <time datetime="2017-06-26T08:50:00.000Z" itemprop="datePublished">2017-06-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/06/26/一些在爬虫中用到的python tricks/">爬虫笔记4</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="一些在爬虫中用到的python-tricks"><a href="#一些在爬虫中用到的python-tricks" class="headerlink" title="一些在爬虫中用到的python tricks"></a>一些在爬虫中用到的python tricks</h3><p><em>string.strip([c])</em></p>
<p>//This method returns a copy of the string in which all chars have been stripped from the beginning and the end of the string.</p>
<p>返回一个string，是原string的copy但删除了所有的c字符。</p>
<p>Reference: <a href="https://www.tutorialspoint.com/python/string_strip.htm" target="_blank" rel="external">https://www.tutorialspoint.com/python/string_strip.htm</a></p>
<p><code>.strip()</code> removes <em>all</em> whitespace at the start and end, including spaces, tabs, newlines and carriage returns. </p>
<p>Reference: <a href="https://stackoverflow.com/questions/13013734/string-strip-in-python" target="_blank" rel="external">https://stackoverflow.com/questions/13013734/string-strip-in-python</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">str.split(str=&quot;&quot;, num=number)</div></pre></td></tr></table></figure>
<p>//str是分隔符，默认是space</p>
<p>举例说明吧，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">str = &quot;Line1-abcdef \nLine2-abc \nLine4-abcd&quot;;</div><div class="line">print str.split( )</div><div class="line">print str.split(&apos; &apos;, 1 )</div></pre></td></tr></table></figure>
<p>结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[&apos;Line1-abcdef&apos;, &apos;Line2-abc&apos;, &apos;Line4-abcd&apos;]</div><div class="line">[&apos;Line1-abcdef&apos;, &apos;\nLine2-abc \nLine4-abcd&apos;]</div></pre></td></tr></table></figure>
<p>Reference: <a href="https://www.tutorialspoint.com/python/string_split.htm" target="_blank" rel="external">https://www.tutorialspoint.com/python/string_split.htm</a></p>
<h3 id="Unicode"><a href="#Unicode" class="headerlink" title="Unicode"></a>Unicode</h3><p> A character is <strong>not, not, not</strong> a byte.  a character is the platonic ideal of the smallest unit of textA.  character encoding defines a mapping between our platonic characters and some way of representing them as bytes. Because there are <u>many ways of representing the same character</u> as bytes, this means that if you have a series of bytes, but do not know their encoding - even if you know the data is textual - the data is meaningless. First thing before everything, is knowing the encoding.</p>
<p>In python, there are three distict string types:</p>
<ol>
<li>‘unicode’, which represents unicode strings (text strings).</li>
<li>‘str’, which represents byte strings (binary data).</li>
<li>‘basestring’, which acts as a parent class for both of the other string types.</li>
</ol>
<p>Conversion between the two types is meaningless without an encoding, Python relies on a ‘default encoding’, specified by sys.setdefaultencoding().</p>
<p>Simply set encoding with function <code>sys.setdefaultencoding()</code> is a solution but may not that good, since the web may use multiple different text encoding.  </p>
<p>Here is a correction solution, referenced from: <a href="http://blog.notdot.net/2010/07/Getting-unicode-right-in-Python" target="_blank" rel="external">http://blog.notdot.net/2010/07/Getting-unicode-right-in-Python</a></p>
<ul>
<li>All <u>text strings</u>, everywhere should be of type unicode, not str. If you’re handling text, and your variable is a str, it’s a bug!</li>
<li>To decode a byte string as text, use var.decode(encoding) (eg, <code>var.decode(&#39;utf-8&#39;)</code>, with the correct encoding. To encode a text string as bytes, use <code>var.encode(encoding)</code>.</li>
<li>Never ever use <code>str()</code> on a unicode string, or <code>unicode()</code> on a byte string without a second argument specifying the encoding.</li>
<li>Whenever you read data from outside your app, expect it to be bytes - eg, of type str - and call .decode() on it to interpret it as text. Likewise, always call .encode() on text you want to send to the outside world.</li>
<li>If a string literal in your code is intended to represent text, it should always be prefixed with ‘u’. In fact, you probably never want to define a raw string literal in your code at all. For what it’s worth, though, I’m terrible at this one, as I’m sure pretty much everyone else is, too.</li>
</ul>
<p>Usually in python 2, for a web crawler python file, I see a lot:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">reload(sys)</div><div class="line">sys.setdefaulyencoding(&apos;utf8&apos;)</div></pre></td></tr></table></figure>
<p>But in python3, default is UTF-8 already. No point to write this again.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/06/26/一些在爬虫中用到的python tricks/" data-id="ck3fyr2eq000ouclvditwgza1" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Avoid Scraper Trapper" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/06/25/Avoid Scraper Trapper/" class="article-date">
  <time datetime="2017-06-25T08:45:57.000Z" itemprop="datePublished">2017-06-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/06/25/Avoid Scraper Trapper/">爬虫笔记3</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="Avoid-Scraper-Trapper"><a href="#Avoid-Scraper-Trapper" class="headerlink" title="Avoid Scraper Trapper"></a>Avoid Scraper Trapper</h3><p>requests library enables use to handle form on website, is algo good at setting headers. HTTP headers contains attributes, preferences, sent by you every time you make a request to server. </p>
<p>Header used by a typical Python scraper using the default url lib library might send:</p>
<p>Accept-Encoding: identity</p>
<p>User-Agent: Python-urllib/3.4</p>
<p>Good website, <a href="https://www.whatismybrowser.com" target="_blank" rel="external">https://www.whatismybrowser.com</a> , to test browser properties viewable by server. </p>
<p>Usually the one setting, that really matters for websites to check for “humanness” based on, is “User-Agent”.</p>
<h3 id="Headers-change-bring-a-lot-conveince"><a href="#Headers-change-bring-a-lot-conveince" class="headerlink" title="Headers change bring a lot conveince"></a>Headers change bring a lot conveince</h3><p>let’s say you need some Chinese material, just simply changing Accept-language: en-US to Accept-Language: zh. </p>
<p>Mobile devices have a different version of web page, so set as this:</p>
<p>User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 7_1_2 like Mac OS X AppleWebKi/537.51.2 (KHTML, like Gecko) Version/7.0 Mobile/11D257)</p>
<p>brings a great change. </p>
<h3 id="Handling-Cookies"><a href="#Handling-Cookies" class="headerlink" title="Handling Cookies"></a>Handling Cookies</h3><p>Cookies can keep you logged in on a site.</p>
<p>There are a number of browser plug-ins that can show you how cookies are being set as you visit and move, <a href="https://www.editthiscookie.com/" target="_blank" rel="external">https://www.editthiscookie.com/</a> , a Chrome extension, is very good.</p>
<p>Request library will be unsable to handle many of the cookies produced by modern software, use Selenium and PhantomJS packages.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">driver = web driver.PhantomJS(executable_path = &apos;&lt;Path to Phantom JS&gt;&apos;)</div><div class="line"></div><div class="line">driver.get(&apos;https://pythonscraping.com&apos;)</div><div class="line"></div><div class="line">driver.implicitly_wait(1)</div><div class="line"></div><div class="line">driver.get_cookies() //save cookies</div><div class="line"></div><div class="line">driver2.delete_all_cookies() //delete all cookies</div><div class="line"></div><div class="line">for cookie in savedCookies:</div><div class="line"></div><div class="line">driver2.add_cookies(cookie)</div><div class="line"></div><div class="line">driver2.get(&quot;http://pythonscraping.com&quot;)</div><div class="line"></div><div class="line">driver.implicitly_wait(1)</div><div class="line"></div><div class="line">print(driver2.get_cookies())</div></pre></td></tr></table></figure>
<h3 id="Timing-Is-Eveything"><a href="#Timing-Is-Eveything" class="headerlink" title="Timing Is Eveything"></a>Timing Is Eveything</h3><p>Even sometimes use multithreaded jobs can make your scraper faster than one single thread, but keep individual page loads and data requests to a minimum, can try to space them by a few seconds, </p>
<p><code>time.sleep(3)</code>.</p>
<p>Reference:</p>
<p>Book:  Web Scraping with Python: Collecting Data from the Modern Web. </p>
<p><a href="https://www.pythonscraping.com/" target="_blank" rel="external">https://www.pythonscraping.com/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/06/25/Avoid Scraper Trapper/" data-id="ck3fyr2dm0000uclvz0llo1r0" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-handling redirects" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/06/24/handling redirects/" class="article-date">
  <time datetime="2017-06-24T08:40:55.000Z" itemprop="datePublished">2017-06-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/06/24/handling redirects/">爬虫笔记2</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="handling-redirects"><a href="#handling-redirects" class="headerlink" title="handling redirects"></a>handling redirects</h3><p>server-side redirect, depending on how it is handled, can be easily traversed by Python’s urllib library without any help from Selenium;</p>
<p>client-side redirects won’t be handled at all unless something is actually executing the javascript.</p>
<p>selenium is capable of handling these Javascript redirects in the same way; when to stop page execution? how to tell when a page is done rediecting? </p>
<p>Detect that redirected in a clever way by watcing an element in the DOM when the page initially loads, then repeatedly calling the element until Selenium throws a StaleElementReferenceException, the element is no longer attached to the page’s DOM and the site has redirected.</p>
<h3 id="Image-Processing-and-Text-Recognition"><a href="#Image-Processing-and-Text-Recognition" class="headerlink" title="Image Processing and Text Recognition"></a>Image Processing and Text Recognition</h3><h5 id="Pillow"><a href="#Pillow" class="headerlink" title="Pillow"></a>Pillow</h5><p>Pillow allows you to easily import and manipulate images iwth a variety of filters, masks, and even pixel-specifc transformations.</p>
<p>from PIL import import Image, ImageFilter</p>
<p>kitten = Image.open(“kitten.jpg”)</p>
<p>blurryKitten = kitten.filter(ImageFilter.GaussianBlur)</p>
<p>blurryKitten.save(“kitten_blurred.jpg”)</p>
<p>blurrykitten.show()</p>
<p>for more useful, <a href="http://pillow.readthedocs.org/" target="_blank" rel="external">http://pillow.readthedocs.org/</a></p>
<h5 id="Tesseract"><a href="#Tesseract" class="headerlink" title="Tesseract"></a>Tesseract</h5><p>scrape text from images on webste.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/06/24/handling redirects/" data-id="ck3fyr2ec000cuclv7e0hijxx" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Expression Expand" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/06/22/Expression Expand/" class="article-date">
  <time datetime="2017-06-22T12:18:00.000Z" itemprop="datePublished">2017-06-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/06/22/Expression Expand/">leetcode/lintcode刷题系－Expression Expand</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="Expression-Expand"><a href="#Expression-Expand" class="headerlink" title="Expression Expand"></a>Expression Expand</h4><p>Given an expression <code>s</code> includes numbers, letters and brackets. Number represents the number of repetitions inside the brackets(can be a string or another expression)．Please expand expression to be a string.</p>
<p><strong>Example</strong>s = <code>abc3[a]</code> return <code>abcaaa</code><br>s = <code>3[abc]</code> return <code>abcabcabc</code><br>s = <code>4[ac]dy</code>, return <code>acacacacdy</code><br>s = <code>3[2[ad]3[pf]]xyz</code>, return <code>adadpfpfpfadadpfpfpfadadpfpfpfxyz</code></p>
<p>语法整理：</p>
<p>Integer.valueOf(int i)//returns an integer object holds the value of specified primitives, 返回一个保存原指定数的整数对象。</p>
<p>Integer.valueOf(String s)//This returns an Integer object holding the value of the specified string representation.返回一个保存原指定string的整数对象。</p>
<p>Stack<object> stack = new Stack<object>(); //a templetate of stack, use explicit conversion to convert to some class.</object></object></p>
<p>Character.isDigit(c) //check if a character is ‘0’-‘9’</p>
<p>Integer count = (Integer)stack.pop();</p>
<p>instanceof //check type of the object</p>
<pre><code>public class Solution {
/**
 * @param s  an expression includes numbers, letters and brackets
 * @return a string
 */
public String expressionExpand(String s) {
    // Write your code here
    Stack&lt;Object&gt; stack = new Stack&lt;Object&gt;();
    int number = 0;
    for(char c: s.toCharArray()){
        if(Character.isDigit(c)){
            number = number * 10 + (c-&apos;0&apos;);
        }else if(c == &apos;[&apos;){
            stack.push(Integer.valueOf(number));
            number = 0;
        }else if(c == &apos;]&apos;){
            String temp = popStack(stack);
            Integer count = (Integer)stack.pop();
            while(count &gt; 0){
                stack.push(temp);
                count--;
            }
        }else{
            stack.push(String.valueOf(c));
        }
    }
    return popStack(stack);
}

String popStack(Stack&lt;Object&gt; stack){
    Stack&lt;String&gt; container = new Stack&lt;String&gt;();
    while(!stack.empty() &amp;&amp; (stack.peek() instanceof String)){
        container.push((String)stack.pop());
    }
    StringBuilder sb = new StringBuilder();
    while(!container.empty()){
        sb.append(container.pop());
    }
    return sb.toString();
 }
}
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/06/22/Expression Expand/" data-id="ck3fyr2dr0001uclvqfjy0ndl" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/leetcode/">leetcode</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/">leetcode</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/强化学习/">强化学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/推荐系统/">推荐系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/深度学习/">深度学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/leetcode/" style="font-size: 20px;">leetcode</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/强化学习/" style="font-size: 15px;">强化学习</a> <a href="/tags/推荐系统/" style="font-size: 10px;">推荐系统</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a> <a href="/tags/爬虫/" style="font-size: 20px;">爬虫</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">June 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/11/25/policy_gradient/">Policy Gradient关键点分析</a>
          </li>
        
          <li>
            <a href="/2019/11/05/Dueling DQN/">Dueling Network Architecture for Deep Reinforcement Learning 论文精读</a>
          </li>
        
          <li>
            <a href="/2018/07/15/Recsys-Spotify-2018-Challenge/">Recsys-Spotify-2018-Challenge比赛总结</a>
          </li>
        
          <li>
            <a href="/2017/11/13/Word2Vec/">Word2Vec模型</a>
          </li>
        
          <li>
            <a href="/2017/11/09/python_script_function/">一些python function总结</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Bowen He<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>