<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Bowen He&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Bowen He&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Bowen He&#39;s Blog">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Bowen He&#39;s Blog">
  
    <link rel="alternate" href="/atom.xml" title="Bowen He&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Bowen He&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">劝君惜取少年时.</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Recsys-Spotify-2018-Challenge" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/15/Recsys-Spotify-2018-Challenge/" class="article-date">
  <time datetime="2018-07-15T14:20:00.000Z" itemprop="datePublished">2018-07-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/15/Recsys-Spotify-2018-Challenge/">Recsys-Spotify-2018-Challenge比赛总结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>ACM（国际计算机学会）主办的推荐系统专场（Recsys）是推荐系统圈子的顶级会议，2018年ACM和spotify联合举办的Recsys challenge，本次比赛一共分为两个track，main track，只能用比赛方提供的数据，creative track，除了比赛方提供的数据还可以用外部数据。我和队友们在本次比赛的main track中，取得public board第六名的成绩，整个比赛，感谢我的老板兼队友提供的很多很好的idea，也让我对数据挖掘有了很多新的思考，这条路我还需要很多持之以恒的努力。</p>
<p><a href="http://www.recsyschallenge.com/2018/" target="_blank" rel="external">http://www.recsyschallenge.com/2018/</a></p>
<h2 id="赛题描述"><a href="#赛题描述" class="headerlink" title="赛题描述"></a>赛题描述</h2><h3 id="数据描述"><a href="#数据描述" class="headerlink" title="数据描述"></a>数据描述</h3><p>本次比赛由ACM Recsys和Spotify联合举办的recsys challenge，赛题给定了一百万的歌单数据集，版权由spotify所有，本文之后将简称该数据集为MSD，具体数据详情见以下：</p>
<p>每个歌单metadata包括</p>
<p>playlist_duration,  歌单整体时长</p>
<p>playlist_title, 歌单名称</p>
<p>track_num, 歌单的单曲数量</p>
<p>last_modified_time, 最后一次修改歌单的时间</p>
<p>track, 每首单曲</p>
<p> each track’s position in the playlist, 每首单曲在歌单中的位置</p>
<p>每首单曲的metadata包括</p>
<p>track_name,  单曲歌名</p>
<p>track_duration, 单曲时长</p>
<p>artist, 单曲歌手</p>
<p>album, 单曲所属专辑</p>
<h3 id="任务描述"><a href="#任务描述" class="headerlink" title="任务描述"></a>任务描述</h3><p>比赛的大目标，即是自动延续歌单，给定一个歌单，歌单已经含有1-250首歌不等，要求预测出500首更高概率会出现在歌单里的单曲，按概率从高到低提交，这个任务在研究领域有个专业名称，playlist auto continuation,  本次比赛分为十个子任务：</p>
<ol>
<li>只给定歌单名，预测500首单曲；</li>
<li>给定歌单名，给定最top的1首歌，预测500首单曲；</li>
<li>给定歌单名，给定按顺序出现的最top的5首歌，预测500首单曲；</li>
<li>不给歌单名，给定按顺序出现的最top的5首歌，预测500首单曲；</li>
<li>给定歌单名，给定按顺序出现的最top的10首歌，预测500首单曲；</li>
<li>不给歌单名，给定按顺序出现的最top的10首歌，预测500首单曲；</li>
<li>给定按顺序出现的最top的25首歌，预测500首单曲；</li>
<li>给定歌单随机位置的25首歌，预测500首单曲；</li>
<li>给定按顺序出现的最top的100首歌，预测500首单曲；</li>
<li>给定歌单随机位置的100首歌，预测500首单曲。</li>
</ol>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>因为此次比赛属于推荐性质的问题，大方法上，我们采用的是based-on item collaborative filtering, 针对赛题里十个子任务各自的特性，我们将十个子任务按其数据特性，分为4种case，对原有cf算法作了4个不同的改进。也是这次比赛，更让我体会到这类推荐任务，甚至数据挖掘想做好的前提，就是要深刻理解数据，根据数据的特性，来采用有效的方法，想起上周同一个比赛，老板eda发现的magic feature，提升了3个百分点，扯远了…</p>
<h3 id="Based-On-Item-Collaborative-Filtering"><a href="#Based-On-Item-Collaborative-Filtering" class="headerlink" title="Based-On Item Collaborative Filtering"></a>Based-On Item Collaborative Filtering</h3><p>这个算法不作过多介绍，推荐算法老牌战斗机，简单概述就是，如果很多user喜欢item A, B, C，那么对于喜欢itemA, B的user，我给他也推荐C，简单的逻辑，好用的算法；</p>
<p>优点：相比based-on user collaborative filtering, based-on item计算更加efficency，因为绝大数多场景，user的数量总是远远过于item的，另外因为user的偏好往往更多元，举个例子，一个人喜欢听周杰伦的‘告白气球’，他也可能喜欢听钢琴曲‘土耳其进行曲’，这是很常见的，可是这两首歌在同一歌单出现的概率，应该不太大，同一歌单中的单曲，应该总有某个部分的相似性，促使它们被放在同一歌单。</p>
<p>缺点：协同过滤的算法，往往会更倾向推荐热门的歌单，使得一些小众的歌得不到重视。</p>
<h3 id="Task1-Subtask-2-3-4-5-6"><a href="#Task1-Subtask-2-3-4-5-6" class="headerlink" title="Task1-Subtask 2,3,4,5,6"></a>Task1-Subtask 2,3,4,5,6</h3><p>上面提到，我们根据不同子任务的数据特性，将2，3，4，5，6这五种子任务，归为同一种任务，按同一算法来推荐；所用的主要方法就是based on item collaborative filtering, 这个方法几乎用在了除子任务1以外的每个子任务：</p>
<p>先根据提供的MSD data构建一个大的item-user矩阵，MSD data中共有100万个歌单，和2262292首distinct的单曲，歌单即是user，单曲即是item，那么这里把所有原始数据构造成了一个大的[2262292, 1000000]的矩阵，本文以后将简称这个矩阵为大矩阵， 注意，就像绝大多数推荐系统的item-user矩阵一样，这个大矩阵有很强的稀疏性，如果初始化用一个稠密矩阵去做，很可能内存就爆了，我们采用了稀疏矩阵的办法，极大的节省了内存</p>
<p>`<br>    import scipy.sparse as sp</p>
<pre><code>mat = sp.dok_matrix((2262292, 1000000), dtype=np.float32)

for song, pids in dic.items():

​    for pid in pids:

​        mat[song, pid] = 1

mat = mat.tocsr().sorted_indices()
</code></pre><p>`</p>
<p>假定歌单中有[A, B, C, D, E]五首歌，先计算A和所有歌曲（2262292）每首歌的相似度，这里的相似度就是依赖A和每首歌曲的共同歌单的数量，对于A和任一单曲，song1，假设只有单曲A出现在歌单list1, list2, list3，song1出现在歌单list3， list4，那么A和song1共同歌单的数量就是1，对song1的打分就是1，依次用A去对2262292每首歌计算共同歌曲分数；再用B去对2262292每首歌计算共同歌曲分数，接着C, D, E，把每首歌的5个结果求平均，再按每首歌得分从高到低排列，选取除掉已出现在歌单中的[A, B, C, D, E]五首歌，剩下的top500，即为我们的推荐歌单；</p>
<p>但这里的问题是，仅仅用共同歌单数，会导致那些热门歌曲，出现在很多歌单的歌，有更高的概率被推荐，这个时候热门的因素会胜过相似的因素，怎么办？很自然可以想到，我们可以用共同歌单数量，除以每首歌各自出现的歌单数量；这样不就可以平衡热门单曲的因素了吗。</p>
<p>在这个思路上，我们参考了这位大佬的论文：</p>
<p><a href="http://www.ke.tu-darmstadt.de/events/PL-12/papers/08-aiolli.pdf" target="_blank" rel="external">http://www.ke.tu-darmstadt.de/events/PL-12/papers/08-aiolli.pdf</a></p>
<p>大佬在论文提出了一个创新的公式，简单概括，这个公式的分母除以了这首歌和被推荐的歌的出现频率的n次方的积；这样可以很好的平衡掉热门歌曲的因素，使得一些小众歌也可以被“平等对待”；</p>
<p>大佬的源码也给出来了，给了我们很好的参考，我们在此基础上作了修改和一些优化，因为我们的数据集更大，同时很稀疏，我们采用了稀疏矩阵方式进行计算，极大的提高了计算速度。</p>
<h3 id="Task2-Subtask-7-9"><a href="#Task2-Subtask-7-9" class="headerlink" title="Task2-Subtask 7,9"></a>Task2-Subtask 7,9</h3><p>这两个子任务都是给定一个歌单的前n首歌，来预测推荐的500首歌。相比之前只给1首歌，5首歌，10首歌，这里的25首歌和100首歌会有一定的序列特征，这个比赛最有意思的地方，就是同一大任务下小任务各自的数据特性，深入挖掘数据特性，应数据制宜，才是提高推荐效果的关键。怎么利用这里的序列特性？之前在Task1中采用的算法，歌单的每首歌都被同等对待了，所有歌曲中一首歌和这整个歌单的相似度，由这首歌和歌单每首歌相似度的平均值来计算；但这里，我们对在靠近尾部的歌，其计算的相似度给了更高的权重，之前是简单的average, 加权重以后变成了weighted average.</p>
<h3 id="Task3-Subtask-8-10"><a href="#Task3-Subtask-8-10" class="headerlink" title="Task3-Subtask 8, 10"></a>Task3-Subtask 8, 10</h3><p>这两个子任务是给定一个歌单随机位置的n首歌，来预测推荐的500首歌。我们在基本算法的基础上，应用上了SLIM。</p>
<h3 id="Task4-Subtask-1"><a href="#Task4-Subtask-1" class="headerlink" title="Task4-Subtask 1"></a>Task4-Subtask 1</h3><p> 之所以把子任务1放到最后来写，是因为这里有很有意思的创新，分享出来希望也能帮到大家。我们以上的基本算法是根据单曲-歌单的共现关系计算相似度进而推荐，但子任务1只给定了歌单名，除此之外没有过多的信息。我们想到，歌单的名字在一定程度上和歌单里的单曲是有很大的关系的，比如一个歌单叫”爱的进行时“，那很大程度，它含有大量的爱情相关的单曲，比如”告白气球“，比如”你问我爱你有多深“，等等；这个时候另一个歌单叫”爱的故事“，那这两个歌单在单曲上应该会有相当大的一部分交集，也就是说，歌单的词-单曲的共现关系也是可以用起来的！延续基本算法，我们构建了词-单曲的稀疏矩阵，作了类似cf的算法，来说说实现细节：</p>
<p>（1）首先是这些歌单名作了一些简单的自然语言处理，pipeline如下：</p>
<p>lower words -&gt; remove repetition characters -&gt; remove special characters</p>
<p>先小写所有字母，去除一个单词中连续重复出现2次以上的字母，只保留一个，最后去掉一些字母以外的特殊符号，这里因为都是英文所以不需要分词处理，source code也给出来了，参考着一个kaggle大佬的kernel写的</p>
<p><a href="https://github.com/LauraBowenHe/Recsys-Spotify-2018-challenge/blob/master/src/utilities/title_preprocess.py#L7" target="_blank" rel="external">https://github.com/LauraBowenHe/Recsys-Spotify-2018-challenge/blob/master/src/utilities/title_preprocess.py#L7</a></p>
<p>（2）我们在第一步处理完，可以得到clean title，这个时候，根据所有单词的unique数量，和所有单曲的数量，做一个 词-单曲的稀疏矩阵，矩阵shape是[词数量，单曲数量2262292]，假设歌单名叫’party’，把’party’这个词那一行，对应的该歌单所有出现的单曲的位置+1，当另一个歌单叫’party dance’，我们把’party’和‘dance‘对应的两行，对应的该歌单所有出现的单曲的位置+1，这样在最终预测时，比如歌单名叫’happy party’, 我们找到’happy’和’party’对应的那两行，[2, 2262292]的相似度小矩阵，求平均，得到[1,2262292]的相似度矩阵，然后和之前一样，按概率从高到低选取top500。</p>
<h2 id="一些赛后想到的idea"><a href="#一些赛后想到的idea" class="headerlink" title="一些赛后想到的idea"></a>一些赛后想到的idea</h2><p>赛后感觉还是有很多可以提高的方法：</p>
<p>task 4中自然语言处理的那部分可以做得再细一点，比如去掉停用词；比如词性stemmerazation和lemmatization，这个在nltk都是有现成的python包的，可以直接调用；</p>
<p>再比如歌单名找词的时候，遇到没有对应词的情况，我直接返回了随机的500首，其实可以用一些fasttext预训练的word embedding, 找出现在矩阵中词集合最相似的近义词；</p>
<p>有一点遗憾，可能加上这些方法，应该会取得更好的名次，但学习的路漫漫，持之以恒才是王道呀。</p>
<h2 id="一些不大成功的尝试"><a href="#一些不大成功的尝试" class="headerlink" title="一些不大成功的尝试"></a>一些不大成功的尝试</h2><h3 id="word2vec"><a href="#word2vec" class="headerlink" title="word2vec"></a>word2vec</h3><p>word2vec其实本质用得也是单曲间共现的关系；类似文本，我们把每个歌单当作一个document，把每首歌当做一个单词，扔到gensim word2vec模型去训练，然后找和歌单中出现的单曲集合最相似的不包含歌单单曲的500首单曲，gensim把代码封装的很好，直接将这个集合丢进去就可以了，不需要每首歌依次计算求平均，这里的代码也分享出来吧</p>
<p>训练的：</p>
<p><a href="https://github.com/LauraBowenHe/Recsys-Spotify-2018-challenge/blob/master/try/word2vec.py" target="_blank" rel="external">https://github.com/LauraBowenHe/Recsys-Spotify-2018-challenge/blob/master/try/word2vec.py</a></p>
<p>预测的：</p>
<p><a href="https://github.com/LauraBowenHe/Recsys-Spotify-2018-challenge/blob/master/try/prediction_v12.py" target="_blank" rel="external">https://github.com/LauraBowenHe/Recsys-Spotify-2018-challenge/blob/master/try/prediction_v12.py</a></p>
<p>但效果并没有协同过滤好，印象中r-precision相差3～4个百分点。</p>
<h3 id="ensemble-cf"><a href="#ensemble-cf" class="headerlink" title="ensemble cf"></a>ensemble cf</h3><p>我们想到，既然能用单曲-歌单的关系，那么artist-歌单的关系，album-歌单的关系，应该都能用吧，计算出来的相似度加权平均效果应该会更好，但实验结果发现，ensemble并无显示提高，有时候甚至有一点点下降，可能的原因，只利用这些例如单曲-歌单的共现关系的话，单曲中已经涵盖了artist和album的信息，很有可能再单独加入使得信息冗余，进而降低准确率。</p>
<h3 id="star-embedding"><a href="#star-embedding" class="headerlink" title="star embedding"></a>star embedding</h3><p>facebook发了一篇很牛逼的论文，大概是说embedding everything，相关代码也开源了，尝试了一下不是很会用。。时间紧迫就没有作过多的探索放弃了</p>
<h2 id="其他选手的方法"><a href="#其他选手的方法" class="headerlink" title="其他选手的方法"></a>其他选手的方法</h2><p>因为举办方要求所有参赛选手把代码开源，于是上github欣赏了一下其他参赛选手的方法，看到挺有意思的也作了简单的总结：</p>
<p>今天太累了…</p>
<p>待续…</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/15/Recsys-Spotify-2018-Challenge/" data-id="cjjmy51rg00032alvdhlfh1sp" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/推荐系统/">推荐系统</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Word2Vec" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/13/Word2Vec/" class="article-date">
  <time datetime="2017-11-13T15:45:00.000Z" itemprop="datePublished">2017-11-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/13/Word2Vec/">Word2Vec模型</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="Stanford-cs224n-2017-lecture2课堂笔记（1）-自己的理解"><a href="#Stanford-cs224n-2017-lecture2课堂笔记（1）-自己的理解" class="headerlink" title="Stanford cs224n 2017 lecture2课堂笔记（1）+ 自己的理解"></a>Stanford cs224n 2017 lecture2课堂笔记（1）+ 自己的理解</h3><p>Reference:</p>
<p><a href="https://web.stanford.edu/class/cs224n/lectures/cs224n-2017-lecture2.pdf" target="_blank" rel="external">https://web.stanford.edu/class/cs224n/lectures/cs224n-2017-lecture2.pdf</a></p>
<p><a href="https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/?blogsub=confirming#subscribe-blog" target="_blank" rel="external">https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/?blogsub=confirming#subscribe-blog</a></p>
<p>正式开笔前，说说废话，下定决心把Stanford这个系列的课上一遍，好好打打自然语言处理的基础，而又因为纯听课的效果对我而言比不上同时更blog做笔记来得好，因此每日多花些时间来写一写。</p>
<h3 id="Why-word2vec"><a href="#Why-word2vec" class="headerlink" title="Why word2vec?"></a>Why word2vec?</h3><p>说到用vector来表达词，一种很常见的方法是离散化的表达，比如one-hot representation, 什么one-hot representation? 假设一个大词库有N个词，想表达Xi, 那么我们就定义一个维度为N的vector，除了第i位为1，其他全为0，举个例子吧：</p>
<p>词库：I have a computer.</p>
<p>每个词的vector为如下形式：</p>
<p>I: [1, 0, 0, 0]</p>
<p>have: [0, 1, 0, 0]</p>
<p>a: [0, 0, 1, 0]</p>
<p>computer: [0, 0, 0, 1]</p>
<p>可是这样离散化表达有什么缺点呢？</p>
<ol>
<li>假设词库很大很大，那么每个词的vector就会很长，后期计算量也会很大，导致我们的模型难以训练；</li>
<li>离散化表达难以体现词和词之间的相互关系，比如一个大的词库里，频繁出现“面膜 护肤”等词，按以上的离散化表达，两个one-hot vector向量的dot multiplication(点乘)是0，难以用cosine等方式计算词和词的相似性。</li>
</ol>
<p>于是～word2vec模型上线，相对于离散化的表达(discrete representation)， word2vec模型属于分布式表达（distributional representation)，which means “distribution of weights across weight”， 也就是说，区别于长度为整个词库数量N的vector，通常用来表示每个词的vector的维数不会很大，而每个element都有一个数，例如lingusitic: [0.7, 0.3, 0.1, 0.2, 0.5]， 这个vector称为词向量，而从单词map到vector这一步，称为word embedding。可见，word2vec通过使用较小维度的vector降低了训练模型需要的space and time complexity，词向量可以通过multiplication(点乘)计算相似性。</p>
<h3 id="两个算法"><a href="#两个算法" class="headerlink" title="两个算法"></a>两个算法</h3><h5 id="Skip-grams-SG"><a href="#Skip-grams-SG" class="headerlink" title="Skip-grams(SG)"></a>Skip-grams(SG)</h5><p>这个算法，是根据给定的词预测词上下文: target -&gt; context</p>
<p>input layer是给定的词，output layer是预测的词上下文，盗了一张参考链接的图：</p>
<p>（原图地址：<a href="https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/?blogsub=confirming#subscribe-blog" target="_blank" rel="external">https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/?blogsub=confirming#subscribe-blog</a>)</p>
<p><img src="/images/word2vec-skip-gram.png" alt=""></p>
<p>在这个模型里，我们把给定的词用one-hot representation表示，vector的长度V即为词库的词数，从input layer映射到hidden layer，我们需要初始化一个W1(VxN)将one-hot转成词向量，因为one-hot的特殊性质举例：[1, 0, 0, 0]，除了特定位置为1，其他位置都为0，因此这个转换词向量的过程，仅仅需要将词向量元素=1的对应的Wmatrix那一行copy就好了，再将hidden layer层乘以W2，得到C个v维词向量，C为word context的词数，每个词向量中，对应位置对高概率的那个词，即为预测词。</p>
<h5 id="Continuous-Bag-of-Words-CBOW"><a href="#Continuous-Bag-of-Words-CBOW" class="headerlink" title="Continuous Bag of Words(CBOW)"></a>Continuous Bag of Words(CBOW)</h5><p>和skip-gram相反，CBOW根据词上下文环境(word context)来预测这个环境中缺失的那个词，举例</p>
<p>I was born in _, so my native language is Madarine. 这里很明显缺失的那个词为China, 而整个语句为word context，我们的output就是要预测的缺失的词。</p>
<p>再盗图一张，来自相同reference链接。</p>
<p><img src="/images/word2vec-cbow.png" alt=""></p>
<p>在这个模型中，input layer中输入的是给定word context中所有词(C个)的one-hot vector(V)，与weights矩阵W1(VxN)相乘，分别得到多词向量vector(N), 取平均值即为hidden layer，再由hidden layer乘以weights矩阵W2(NxV)得到output词向量v，维度为V，最高分数的那一维度对应的词就是predict word。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/13/Word2Vec/" data-id="cjjmy51rl00052alv3svmxc7v" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/深度学习/">深度学习</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-python_script_function" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/09/python_script_function/" class="article-date">
  <time datetime="2017-11-09T15:07:00.000Z" itemprop="datePublished">2017-11-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/09/python_script_function/">一些python function总结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>今天看一份代码的时候，有些python function不知其何用，想来写个博客把每次遇到的总结在一篇blog，可以时常看看。</p>
<h3 id="print-doc"><a href="#print-doc" class="headerlink" title="print(__doc__)"></a><code>print(__doc__)</code></h3><p>这个可以print出python file or function中注释部分，比如：</p>
<p> in module.py:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&quot;&quot;&quot;This is the module file, use for provide a function.&quot;&quot;&quot;</div><div class="line">def func(x):</div><div class="line">	return x</div><div class="line">&gt;&gt;&gt;import module</div><div class="line">&gt;&gt;&gt;print(module.__doc__)</div><div class="line">&gt;&gt;&gt;&apos;This is the module file, use for provide a function.&apos;</div></pre></td></tr></table></figure>
<h3 id="把一个list的string转成float"><a href="#把一个list的string转成float" class="headerlink" title="把一个list的string转成float"></a>把一个list的string转成float</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; nums = [&apos;1.0&apos;,&apos;2.0&apos;]</div><div class="line">&gt;&gt;&gt; float_nums = list(map(float, nums))</div></pre></td></tr></table></figure>
<h3 id="随机数Random-Module"><a href="#随机数Random-Module" class="headerlink" title="随机数Random Module"></a>随机数Random Module</h3><h5 id="均一分布（uniform）随机数"><a href="#均一分布（uniform）随机数" class="headerlink" title="均一分布（uniform）随机数"></a>均一分布（uniform）随机数</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt;random.unifrom(a, b)</div></pre></td></tr></table></figure>
<h5 id="两数范围内的随机整数"><a href="#两数范围内的随机整数" class="headerlink" title="两数范围内的随机整数"></a>两数范围内的随机整数</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; random.randint(a,b)</div></pre></td></tr></table></figure>
<h5 id="从sequence中随机选择一个element"><a href="#从sequence中随机选择一个element" class="headerlink" title="从sequence中随机选择一个element"></a>从sequence中随机选择一个element</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; nums = [&quot;blue&quot;, &quot;green&quot;]</div><div class="line">&gt;&gt;&gt; random.choice(nums)</div></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/09/python_script_function/" data-id="cjjmy51s2000h2alv8ge4ym5o" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-kaggle_dog_breed_idnentification" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/11/04/kaggle_dog_breed_idnentification/" class="article-date">
  <time datetime="2017-11-04T08:50:00.000Z" itemprop="datePublished">2017-11-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/11/04/kaggle_dog_breed_idnentification/">kaggle dog breed identification基于Tensorflow迁移学习搭建图片分类器</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="基于Tensorflow的迁移学习应用-kaggle-dog-breed-identification构建新图片分类器"><a href="#基于Tensorflow的迁移学习应用-kaggle-dog-breed-identification构建新图片分类器" class="headerlink" title="基于Tensorflow的迁移学习应用 kaggle dog breed identification构建新图片分类器"></a>基于Tensorflow的迁移学习应用 kaggle dog breed identification构建新图片分类器</h3><p>本文所用数据来源于<a href="https://www.kaggle.com/c/dog-breed-identification" target="_blank" rel="external">https://www.kaggle.com/c/dog-breed-identification</a>, 将基于google tensorflow中的预训练的mobilenet模型和inception v3模型，对新dataset中10200张不同狗品种照片训练新的图片分类。</p>
<h4 id="Why-transfer-learning-here"><a href="#Why-transfer-learning-here" class="headerlink" title="Why transfer learning here?"></a>Why transfer learning here?</h4><ol>
<li>一个好的图片分类器，从scratch开始搭建，不仅构建cnn archtiecture会花费大量的时间精力，而且为了分类器的精准度，也需要大量的图片作为training data。</li>
<li>而实际应用中，针对不用需要而构建的分类器，通常只有小量的数据集，从scratch开始训练一个巨大的拥有百万甚至更多的parameters的cnn分类器很容导致过拟合，而使训练出的分类器在general set上表现不佳。</li>
<li>我们将使用的经过预训练的mobilenet模型和inception v3模型，是google基于 <a href="http://www.image-net.org/" target="_blank" rel="external">ImageNet</a> , 一个计算机视觉系统识别项目，目前世界上图像识别最大的数据库，其包含了分成了数千个类型、数百万张有标注的图像, 训练出的两个分类器模型，其Top-1 accuracy 分别达到78.0%和70.7%，inception v3会有更好的accuray，而mobilenet因为其轻量，训练速度更快。</li>
<li>针对与原数据库相似但size较小的数据集，使用transfer learning，将已根据</li>
</ol>
<h3 id="基于MobileNet的新分类器搭建"><a href="#基于MobileNet的新分类器搭建" class="headerlink" title="基于MobileNet的新分类器搭建"></a>基于MobileNet的新分类器搭建</h3><h5 id="准备阶段，get-code"><a href="#准备阶段，get-code" class="headerlink" title="准备阶段，get code"></a>准备阶段，get code</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/googlecodelabs/tensorflow-for-poets-2</div><div class="line">cd tensorflow-for-poets-2</div></pre></td></tr></table></figure>
<h5 id="准备阶段，get-dataset"><a href="#准备阶段，get-dataset" class="headerlink" title="准备阶段，get dataset"></a>准备阶段，get dataset</h5><p><a href="https://www.kaggle.com/c/dog-breed-identification" target="_blank" rel="external">https://www.kaggle.com/c/dog-breed-identification</a>, 下载training dataset, labels.csv和test dataset,</p>
<h5 id="预处理数据集"><a href="#预处理数据集" class="headerlink" title="预处理数据集"></a>预处理数据集</h5><p>我们直接下载得到的训练数据集中，只有所有的图片在同一个数据集，我们需要整理成模型需要的格式，即在同一个directory下，将每个label建一个subdirectory，将所有对应的图片放入当前subdirectory下，参考code可见:</p>
<p><a href="https://github.com/LauraBowenHe/dog-breed-identification/blob/master/MobileNet/classify_pic_to_dir.py" target="_blank" rel="external">https://github.com/LauraBowenHe/dog-breed-identification/blob/master/MobileNet/classify_pic_to_dir.py</a></p>
<h5 id="配置MobileNet"><a href="#配置MobileNet" class="headerlink" title="配置MobileNet"></a>配置MobileNet</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">IMAGE_SIZE=224</div><div class="line">ARCHITECTURE=&quot;mobilenet_1.0_$&#123;IMAGE_SIZE&#125;&quot;</div></pre></td></tr></table></figure>
<p>注意这里：</p>
<p>IMAGE_SIZE, 即image resolution配置的参数：128,160,192, or 224px。当然越高的resolution可以带来更高的accuray，同时也需要更多的训练时间。</p>
<p>相对模型size占最大largest MobileNet的比例: 1.0, 0.75, 0.50, or 0.25. 同样，所占比例越大，accuracy越高，也需要更多的训练时间。</p>
<p>在这个任务中，我们希望获得更可能高的accuray，所以采取以上配置。</p>
<h5 id="用tensorboard监控训练过程"><a href="#用tensorboard监控训练过程" class="headerlink" title="用tensorboard监控训练过程"></a>用tensorboard监控训练过程</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tensorboard --logdir tf_files/training_summaries &amp;</div></pre></td></tr></table></figure>
<p>在后台启用tensorboard，tensorboard可以用来监控训练过程，帮助我们更好判断是否过拟合等。</p>
<p>训练完成后，可以在浏览器输入</p>
<p><a href="http://localhost:6006" target="_blank" rel="external">http://localhost:6006</a> </p>
<p>or <a href="http://0.0.0.0:6006即可看到tensorboard为我们绘画的各种训练过程图像。" target="_blank" rel="external">http://0.0.0.0:6006即可看到tensorboard为我们绘画的各种训练过程图像。</a></p>
<h5 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">python -m scripts.retrain \</div><div class="line">  --bottleneck_dir=tf_files/bottlenecks \</div><div class="line">  --how_many_training_steps=3000 \</div><div class="line">  </div><div class="line">  --model_dir=tf_files/models/ \</div><div class="line">  --summaries_dir=tf_files/training_summaries/&quot;$&#123;ARCHITECTURE&#125;&quot; \</div><div class="line">  --output_graph=tf_files/retrained_graph.pb \</div><div class="line">  --output_labels=tf_files/retrained_labels.txt \</div><div class="line">  --architecture=&quot;$&#123;ARCHITECTURE&#125;&quot; \</div><div class="line">  --image_dir=tf_files/dog_photos</div></pre></td></tr></table></figure>
<p>注意：</p>
<ol>
<li><p>在这里，把我们之前预处理过的数据集，让在tf_files directory下。</p>
</li>
<li><p>optionally，我们可以添加更多的训练参数，详情可以参考</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">python -m scripts.retrain -h</div><div class="line">我加入了以下的参数</div><div class="line">--training_rate=0.001 \</div><div class="line">--train_batch_size=64 \</div></pre></td></tr></table></figure>
</li>
</ol>
<h5 id="调参"><a href="#调参" class="headerlink" title="调参"></a>调参</h5><p>调节training steps， training rate， train batch size等等。</p>
<h5 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h5><p>对于单个图片，可以用source code中的label_image.py</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">python -m scripts.label_image \</div><div class="line">    --graph=tf_files/retrained_graph.pb  \</div><div class="line">    --image=tf_files/flower_photos/daisy/21652746_cc379e0eea_m.jpg</div></pre></td></tr></table></figure>
<p>而针对这个狗品种分类器的任务，我们把从kaggle上下载的test dataset也放入tf_files directory下，修改了一下source中的label_image.py，增加新的文件generate_result.py, 对每个文件依次调用label_image.py，code可见</p>
<p><a href="https://github.com/LauraBowenHe/dog-breed-identification/blob/master/MobileNet/scripts/label_image.py" target="_blank" rel="external">https://github.com/LauraBowenHe/dog-breed-identification/blob/master/MobileNet/scripts/label_image.py</a></p>
<p><a href="https://github.com/LauraBowenHe/dog-breed-identification/tree/master/MobileNet" target="_blank" rel="external">https://github.com/LauraBowenHe/dog-breed-identification/tree/master/MobileNet</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python generate_result.py</div></pre></td></tr></table></figure>
<p>这一步预测时间会比较长，大概7-8小时，生成的文件会存在/tensorflow-poets-2/output/下，我们在训练前可先手动创建这个文件夹。</p>
<h3 id="基于inception-v3的新分类器搭建"><a href="#基于inception-v3的新分类器搭建" class="headerlink" title="基于inception v3的新分类器搭建"></a>基于inception v3的新分类器搭建</h3><p>inception v3的搭建和mobilenet很相似，只有在get code时有所不同。</p>
<h5 id="准备阶段，get-code-1"><a href="#准备阶段，get-code-1" class="headerlink" title="准备阶段，get code"></a>准备阶段，get code</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ git clone https://github.com/tensorflow/tensorflow</div><div class="line">$ cd tensorflow</div><div class="line">$ git checkout</div></pre></td></tr></table></figure>
<h5 id="准备阶段-get-dataset和预处理数据集"><a href="#准备阶段-get-dataset和预处理数据集" class="headerlink" title="准备阶段,  get dataset和预处理数据集"></a>准备阶段,  get dataset和预处理数据集</h5><p>参考以上</p>
<h5 id="训练模型-1"><a href="#训练模型-1" class="headerlink" title="训练模型"></a>训练模型</h5><p>retrain的代码在/examples/image_retraining，我们可以直接用刚刚mobilenet模型中，/tensorflow-for-poet-2/tf_files，因为我们之前已经有把数据集都放在那里了，当然即使没有也没关系，新建一个tf_files就行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">python retrain.py \</div><div class="line">  --bottleneck_dir=~/tensorflow-for-poets-2/tf_files/bottlenecks \</div><div class="line">  --how_many_training_steps=500 \</div><div class="line">  --model_dir=~/tensorflow-for-poets-2/tf_files/inception \</div><div class="line">  --summaries_dir=~/tensorflow-for-poets-2/tf_files/training_summaries/basic \</div><div class="line">  --output_graph=~/tensorflow-for-poets-2/tf_files/retrained_graph.pb \</div><div class="line">  --output_labels=~/tensorflow-for-poets-2/tf_files/retrained_labels.txt \</div><div class="line">  --image_dir=~/tensorflow-for-poets-2/tf_files/dog_photos</div></pre></td></tr></table></figure>
<p><code>python -m retrain.py -h 可以查阅可以添加的参数</code></p>
<p>附一张训练结束的图，可见当前分类器的validation accuracy是90.3%。</p>
<p><img src="/Users/bowenhe/Desktop/Screen Shot 2017-11-04 at 3.59.56 PM.png" alt="Screen Shot 2017-11-04 at 3.59.56 PM"></p>
<h5 id="调参-1"><a href="#调参-1" class="headerlink" title="调参"></a>调参</h5><p>调节training steps， training rate， train batch size等等。</p>
<h5 id="预测-1"><a href="#预测-1" class="headerlink" title="预测"></a>预测</h5><p>因为我们已将生成的模型放入tf_files。我们把从kaggle上下载的test dataset也放入tf_files directory下，创建了一份label_image_inceptionV3.py，增加新的文件generate_result_inceptionV3.py, 对每个文件依次调用label_image_inceptionV3.py，code可见</p>
<p><a href="https://github.com/LauraBowenHe/dog-breed-identification/blob/master/InceptionV3/label_image_inceptionV3.py" target="_blank" rel="external">https://github.com/LauraBowenHe/dog-breed-identification/blob/master/InceptionV3/label_image_inceptionV3.py</a></p>
<p><a href="https://github.com/LauraBowenHe/dog-breed-identification/blob/master/InceptionV3/generate_result_inceptionV3.py" target="_blank" rel="external">https://github.com/LauraBowenHe/dog-breed-identification/blob/master/InceptionV3/generate_result_inceptionV3.py</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python generate_result_inceptionV3.py</div></pre></td></tr></table></figure>
<p>这一步预测时间会比较长，比MobileNet所用的时间更长，大概在十四个小时，生成的文件会存在/tensorflow-poets-2/output/下，我们在训练前可先手动创建这个文件夹。</p>
<h5 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h5><p><a href="http://cs231n.github.io/transfer-learning/" target="_blank" rel="external">http://cs231n.github.io/transfer-learning/</a></p>
<p><a href="https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0" target="_blank" rel="external">https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0</a></p>
<p><a href="https://www.ouyangsong.com/2017/05/20/image-classification-retrained-based-on-inceptionv3/" target="_blank" rel="external">https://www.ouyangsong.com/2017/05/20/image-classification-retrained-based-on-inceptionv3/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/11/04/kaggle_dog_breed_idnentification/" data-id="cjjmy51rz000c2alv36huncgi" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/深度学习/">深度学习</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-一些在爬虫中用到的python tricks" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/06/26/一些在爬虫中用到的python tricks/" class="article-date">
  <time datetime="2017-06-26T08:50:00.000Z" itemprop="datePublished">2017-06-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/06/26/一些在爬虫中用到的python tricks/">爬虫笔记4</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="一些在爬虫中用到的python-tricks"><a href="#一些在爬虫中用到的python-tricks" class="headerlink" title="一些在爬虫中用到的python tricks"></a>一些在爬虫中用到的python tricks</h3><p><em>string.strip([c])</em></p>
<p>//This method returns a copy of the string in which all chars have been stripped from the beginning and the end of the string.</p>
<p>返回一个string，是原string的copy但删除了所有的c字符。</p>
<p>Reference: <a href="https://www.tutorialspoint.com/python/string_strip.htm" target="_blank" rel="external">https://www.tutorialspoint.com/python/string_strip.htm</a></p>
<p><code>.strip()</code> removes <em>all</em> whitespace at the start and end, including spaces, tabs, newlines and carriage returns. </p>
<p>Reference: <a href="https://stackoverflow.com/questions/13013734/string-strip-in-python" target="_blank" rel="external">https://stackoverflow.com/questions/13013734/string-strip-in-python</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">str.split(str=&quot;&quot;, num=number)</div></pre></td></tr></table></figure>
<p>//str是分隔符，默认是space</p>
<p>举例说明吧，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">str = &quot;Line1-abcdef \nLine2-abc \nLine4-abcd&quot;;</div><div class="line">print str.split( )</div><div class="line">print str.split(&apos; &apos;, 1 )</div></pre></td></tr></table></figure>
<p>结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[&apos;Line1-abcdef&apos;, &apos;Line2-abc&apos;, &apos;Line4-abcd&apos;]</div><div class="line">[&apos;Line1-abcdef&apos;, &apos;\nLine2-abc \nLine4-abcd&apos;]</div></pre></td></tr></table></figure>
<p>Reference: <a href="https://www.tutorialspoint.com/python/string_split.htm" target="_blank" rel="external">https://www.tutorialspoint.com/python/string_split.htm</a></p>
<h3 id="Unicode"><a href="#Unicode" class="headerlink" title="Unicode"></a>Unicode</h3><p> A character is <strong>not, not, not</strong> a byte.  a character is the platonic ideal of the smallest unit of textA.  character encoding defines a mapping between our platonic characters and some way of representing them as bytes. Because there are <u>many ways of representing the same character</u> as bytes, this means that if you have a series of bytes, but do not know their encoding - even if you know the data is textual - the data is meaningless. First thing before everything, is knowing the encoding.</p>
<p>In python, there are three distict string types:</p>
<ol>
<li>‘unicode’, which represents unicode strings (text strings).</li>
<li>‘str’, which represents byte strings (binary data).</li>
<li>‘basestring’, which acts as a parent class for both of the other string types.</li>
</ol>
<p>Conversion between the two types is meaningless without an encoding, Python relies on a ‘default encoding’, specified by sys.setdefaultencoding().</p>
<p>Simply set encoding with function <code>sys.setdefaultencoding()</code> is a solution but may not that good, since the web may use multiple different text encoding.  </p>
<p>Here is a correction solution, referenced from: <a href="http://blog.notdot.net/2010/07/Getting-unicode-right-in-Python" target="_blank" rel="external">http://blog.notdot.net/2010/07/Getting-unicode-right-in-Python</a></p>
<ul>
<li>All <u>text strings</u>, everywhere should be of type unicode, not str. If you’re handling text, and your variable is a str, it’s a bug!</li>
<li>To decode a byte string as text, use var.decode(encoding) (eg, <code>var.decode(&#39;utf-8&#39;)</code>, with the correct encoding. To encode a text string as bytes, use <code>var.encode(encoding)</code>.</li>
<li>Never ever use <code>str()</code> on a unicode string, or <code>unicode()</code> on a byte string without a second argument specifying the encoding.</li>
<li>Whenever you read data from outside your app, expect it to be bytes - eg, of type str - and call .decode() on it to interpret it as text. Likewise, always call .encode() on text you want to send to the outside world.</li>
<li>If a string literal in your code is intended to represent text, it should always be prefixed with ‘u’. In fact, you probably never want to define a raw string literal in your code at all. For what it’s worth, though, I’m terrible at this one, as I’m sure pretty much everyone else is, too.</li>
</ul>
<p>Usually in python 2, for a web crawler python file, I see a lot:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">reload(sys)</div><div class="line">sys.setdefaulyencoding(&apos;utf8&apos;)</div></pre></td></tr></table></figure>
<p>But in python3, default is UTF-8 already. No point to write this again.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/06/26/一些在爬虫中用到的python tricks/" data-id="cjjmy51s5000j2alv582reygo" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Avoid Scraper Trapper" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/06/25/Avoid Scraper Trapper/" class="article-date">
  <time datetime="2017-06-25T08:45:57.000Z" itemprop="datePublished">2017-06-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/06/25/Avoid Scraper Trapper/">爬虫笔记3</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="Avoid-Scraper-Trapper"><a href="#Avoid-Scraper-Trapper" class="headerlink" title="Avoid Scraper Trapper"></a>Avoid Scraper Trapper</h3><p>requests library enables use to handle form on website, is algo good at setting headers. HTTP headers contains attributes, preferences, sent by you every time you make a request to server. </p>
<p>Header used by a typical Python scraper using the default url lib library might send:</p>
<p>Accept-Encoding: identity</p>
<p>User-Agent: Python-urllib/3.4</p>
<p>Good website, <a href="https://www.whatismybrowser.com" target="_blank" rel="external">https://www.whatismybrowser.com</a> , to test browser properties viewable by server. </p>
<p>Usually the one setting, that really matters for websites to check for “humanness” based on, is “User-Agent”.</p>
<h3 id="Headers-change-bring-a-lot-conveince"><a href="#Headers-change-bring-a-lot-conveince" class="headerlink" title="Headers change bring a lot conveince"></a>Headers change bring a lot conveince</h3><p>let’s say you need some Chinese material, just simply changing Accept-language: en-US to Accept-Language: zh. </p>
<p>Mobile devices have a different version of web page, so set as this:</p>
<p>User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 7_1_2 like Mac OS X AppleWebKi/537.51.2 (KHTML, like Gecko) Version/7.0 Mobile/11D257)</p>
<p>brings a great change. </p>
<h3 id="Handling-Cookies"><a href="#Handling-Cookies" class="headerlink" title="Handling Cookies"></a>Handling Cookies</h3><p>Cookies can keep you logged in on a site.</p>
<p>There are a number of browser plug-ins that can show you how cookies are being set as you visit and move, <a href="https://www.editthiscookie.com/" target="_blank" rel="external">https://www.editthiscookie.com/</a> , a Chrome extension, is very good.</p>
<p>Request library will be unsable to handle many of the cookies produced by modern software, use Selenium and PhantomJS packages.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">driver = web driver.PhantomJS(executable_path = &apos;&lt;Path to Phantom JS&gt;&apos;)</div><div class="line"></div><div class="line">driver.get(&apos;https://pythonscraping.com&apos;)</div><div class="line"></div><div class="line">driver.implicitly_wait(1)</div><div class="line"></div><div class="line">driver.get_cookies() //save cookies</div><div class="line"></div><div class="line">driver2.delete_all_cookies() //delete all cookies</div><div class="line"></div><div class="line">for cookie in savedCookies:</div><div class="line"></div><div class="line">driver2.add_cookies(cookie)</div><div class="line"></div><div class="line">driver2.get(&quot;http://pythonscraping.com&quot;)</div><div class="line"></div><div class="line">driver.implicitly_wait(1)</div><div class="line"></div><div class="line">print(driver2.get_cookies())</div></pre></td></tr></table></figure>
<h3 id="Timing-Is-Eveything"><a href="#Timing-Is-Eveything" class="headerlink" title="Timing Is Eveything"></a>Timing Is Eveything</h3><p>Even sometimes use multithreaded jobs can make your scraper faster than one single thread, but keep individual page loads and data requests to a minimum, can try to space them by a few seconds, </p>
<p><code>time.sleep(3)</code>.</p>
<p>Reference:</p>
<p>Book:  Web Scraping with Python: Collecting Data from the Modern Web. </p>
<p><a href="https://www.pythonscraping.com/" target="_blank" rel="external">https://www.pythonscraping.com/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/06/25/Avoid Scraper Trapper/" data-id="cjjmy51r300002alvnv6zlzm6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-handling redirects" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/06/24/handling redirects/" class="article-date">
  <time datetime="2017-06-24T08:40:55.000Z" itemprop="datePublished">2017-06-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/06/24/handling redirects/">爬虫笔记2</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="handling-redirects"><a href="#handling-redirects" class="headerlink" title="handling redirects"></a>handling redirects</h3><p>server-side redirect, depending on how it is handled, can be easily traversed by Python’s urllib library without any help from Selenium;</p>
<p>client-side redirects won’t be handled at all unless something is actually executing the javascript.</p>
<p>selenium is capable of handling these Javascript redirects in the same way; when to stop page execution? how to tell when a page is done rediecting? </p>
<p>Detect that redirected in a clever way by watcing an element in the DOM when the page initially loads, then repeatedly calling the element until Selenium throws a StaleElementReferenceException, the element is no longer attached to the page’s DOM and the site has redirected.</p>
<h3 id="Image-Processing-and-Text-Recognition"><a href="#Image-Processing-and-Text-Recognition" class="headerlink" title="Image Processing and Text Recognition"></a>Image Processing and Text Recognition</h3><h5 id="Pillow"><a href="#Pillow" class="headerlink" title="Pillow"></a>Pillow</h5><p>Pillow allows you to easily import and manipulate images iwth a variety of filters, masks, and even pixel-specifc transformations.</p>
<p>from PIL import import Image, ImageFilter</p>
<p>kitten = Image.open(“kitten.jpg”)</p>
<p>blurryKitten = kitten.filter(ImageFilter.GaussianBlur)</p>
<p>blurryKitten.save(“kitten_blurred.jpg”)</p>
<p>blurrykitten.show()</p>
<p>for more useful, <a href="http://pillow.readthedocs.org/" target="_blank" rel="external">http://pillow.readthedocs.org/</a></p>
<h5 id="Tesseract"><a href="#Tesseract" class="headerlink" title="Tesseract"></a>Tesseract</h5><p>scrape text from images on webste.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/06/24/handling redirects/" data-id="cjjmy51ru00092alvbzr4aw2a" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Expression Expand" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/06/22/Expression Expand/" class="article-date">
  <time datetime="2017-06-22T12:18:00.000Z" itemprop="datePublished">2017-06-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/06/22/Expression Expand/">leetcode/lintcode刷题系－Expression Expand</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="Expression-Expand"><a href="#Expression-Expand" class="headerlink" title="Expression Expand"></a>Expression Expand</h4><p>Given an expression <code>s</code> includes numbers, letters and brackets. Number represents the number of repetitions inside the brackets(can be a string or another expression)．Please expand expression to be a string.</p>
<p><strong>Example</strong>s = <code>abc3[a]</code> return <code>abcaaa</code><br>s = <code>3[abc]</code> return <code>abcabcabc</code><br>s = <code>4[ac]dy</code>, return <code>acacacacdy</code><br>s = <code>3[2[ad]3[pf]]xyz</code>, return <code>adadpfpfpfadadpfpfpfadadpfpfpfxyz</code></p>
<p>语法整理：</p>
<p>Integer.valueOf(int i)//returns an integer object holds the value of specified primitives, 返回一个保存原指定数的整数对象。</p>
<p>Integer.valueOf(String s)//This returns an Integer object holding the value of the specified string representation.返回一个保存原指定string的整数对象。</p>
<p>Stack<object> stack = new Stack<object>(); //a templetate of stack, use explicit conversion to convert to some class.</object></object></p>
<p>Character.isDigit(c) //check if a character is ‘0’-‘9’</p>
<p>Integer count = (Integer)stack.pop();</p>
<p>instanceof //check type of the object</p>
<pre><code>public class Solution {
/**
 * @param s  an expression includes numbers, letters and brackets
 * @return a string
 */
public String expressionExpand(String s) {
    // Write your code here
    Stack&lt;Object&gt; stack = new Stack&lt;Object&gt;();
    int number = 0;
    for(char c: s.toCharArray()){
        if(Character.isDigit(c)){
            number = number * 10 + (c-&apos;0&apos;);
        }else if(c == &apos;[&apos;){
            stack.push(Integer.valueOf(number));
            number = 0;
        }else if(c == &apos;]&apos;){
            String temp = popStack(stack);
            Integer count = (Integer)stack.pop();
            while(count &gt; 0){
                stack.push(temp);
                count--;
            }
        }else{
            stack.push(String.valueOf(c));
        }
    }
    return popStack(stack);
}

String popStack(Stack&lt;Object&gt; stack){
    Stack&lt;String&gt; container = new Stack&lt;String&gt;();
    while(!stack.empty() &amp;&amp; (stack.peek() instanceof String)){
        container.push((String)stack.pop());
    }
    StringBuilder sb = new StringBuilder();
    while(!container.empty()){
        sb.append(container.pop());
    }
    return sb.toString();
 }
}
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/06/22/Expression Expand/" data-id="cjjmy51r900012alvlme1who0" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/leetcode/">leetcode</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Sliding Window Median" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/06/22/Sliding Window Median/" class="article-date">
  <time datetime="2017-06-22T07:51:00.000Z" itemprop="datePublished">2017-06-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/06/22/Sliding Window Median/">leetcode/lintcode刷题系－Sliding Window Median</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="Sliding-Window-Median"><a href="#Sliding-Window-Median" class="headerlink" title="Sliding Window Median"></a>Sliding Window Median</h4><p>Question: Given an array of n integer, and a moving window(size k), move the window at each iteration from the start of the array, find the median of the element inside the window at each moving. (If there are even numbers in the array, return the N/2-th number after sorting the element in the window. )</p>
<p><strong>Example</strong>For array <code>[1,2,7,8,5]</code>, moving window size k = 3. return <code>[2,7,7]</code>At first the window is at the start of the array like this<code>[ | 1,2,7 | ,8,5]</code> , return the median <code>2</code>;then the window move one step forward.<code>[1, | 2,7,8 | ,5]</code>, return the median <code>7</code>;then the window move one step forward again.<code>[1,2, | 7,8,5 | ]</code>, return the median <code>7</code>;</p>
<h5 id="分析："><a href="#分析：" class="headerlink" title="分析："></a>分析：</h5><ol>
<li>首先，这道题目是一道移动窗口求中位数类的问题，对于动态求中位数的问题，通常我会用heap的模版来处理，即维持两个heap，minheap和maxheap，maxheap来存放所有比中位数小的及相等的数＋中位数，minheap存放所有比中位数大的数；举例说明，当我们的数组是［1，2，7］，这个时候maxheap存放［1，2］，minheap存放［7］，中位数就是maxheap里的最大值，当有新的数进来或者旧的数出去的时候，我们每次都和当前median的大小来比较，决定放入哪个heap，再根据左右两边size的大小进行相应调整，永远满足median是 N/2-th number。</li>
<li>选用什么数据结构？因为这里的动态窗口还要求删除被移除窗口的元素，所以我们需要一个数据结构，既能满足heap的性质，又能满足定点删除的性质，于是想到了hashheap！java中TreeSet正好满足。</li>
<li>这里有一个tricky的点在于，因为input中的输入点可能是duplicated，直接把数放到treeset中，不能存下duplicated elements，怎么解决？想到了可以构造一个class，同时包含这个element在input array的位置，即id，还包含这个element的value，那么我们将得到unique的object。</li>
</ol>
<p>代码：</p>
<pre><code>public class Solution {
/**
 * @param nums: A list of integers.
 * @return: The median of the element inside the window at each moving.
 */
public Node insertNum(Node median, Node currNode, TreeSet&lt;Node&gt; minheap, TreeSet&lt;Node&gt; maxheap){
    /* median is put on the maxheap */
    if(maxheap.size() == 0 &amp;&amp; minheap.size() == 0){
        maxheap.add(currNode);
        return currNode;
    }
    if(currNode.val &lt;= median.val){

        if(maxheap.size()-minheap.size() &lt; 1){
            maxheap.add(currNode);
            median = maxheap.last();
        }else{
            minheap.add(median);
            maxheap.remove(median);
            maxheap.add(currNode);
            median = maxheap.last();
        }
    }else{
        if(maxheap.size() &gt; minheap.size() ){
            minheap.add(currNode);
        }else{
            minheap.add(currNode);
            median = minheap.first();
            maxheap.add(median);
            minheap.remove(median);
        }
    }
    return median;
}

public ArrayList&lt;Integer&gt; medianSlidingWindow(int[] nums, int k) {
    // write your code here
    ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();
    if(nums.length == 0 || k &lt;= 0 || nums.length &lt; k){
        return list;
    }

    TreeSet&lt;Node&gt; minheap = new TreeSet&lt;Node&gt;();
    TreeSet&lt;Node&gt; maxheap = new TreeSet&lt;Node&gt;();

    Node median = new Node(0, nums[0]);
    maxheap.add(median);
    for(int i = 1; i &lt; k; i++){
        Node currNode = new Node(i, nums[i]);
        median = insertNum(median,  currNode, minheap, maxheap);
    }
    list.add(median.val);

    for(int i = k; i &lt; nums.length; i++){
        Node currNode = new Node(i, nums[i]);
        Node prevNode = new Node(i-k, nums[i-k]);
        if (minheap.contains(prevNode)) {
            minheap.remove(prevNode);
        }
        else{
            maxheap.remove(prevNode);
        }

        median = insertNum(median, currNode, minheap, maxheap);
        list.add(median.val);
    }
    return list;
  }

}

/* construct node class */
class Node implements Comparable&lt;Node&gt;{
    int id;
    int val;
    Node(int id, int val){
        this.id = id;
        this.val = val;
    }
    /* construct compareTo method, to make sure the elements is sorted by val or ID when vals are same */
    public int compareTo(Node other){
        if(this.val == other.val){
            return this.id-other.id;
        }
        return this.val-other.val;
    }
}
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/06/22/Sliding Window Median/" data-id="cjjmy51ri00042alvjv8l8w8f" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/leetcode/">leetcode</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-爬虫中遇到的登录login和form" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/06/21/爬虫中遇到的登录login和form/" class="article-date">
  <time datetime="2017-06-21T15:21:57.000Z" itemprop="datePublished">2017-06-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/06/21/爬虫中遇到的登录login和form/">爬虫中关于登录网页，文件上传的一些笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="爬虫中遇到的登录login和form"><a href="#爬虫中遇到的登录login和form" class="headerlink" title="爬虫中遇到的登录login和form"></a>爬虫中遇到的登录login和form</h3><p>大多数web form都是由一些HTML field, submit button, 以及一个”action” page，即form真正被处理的地方，共同组成。举例说明，以下为一个最基本的web form:<a href="">http://pythonscraping.com/pages/files/form.html</a>, 可以用chrome浏览器，view-developer-source code查看html代码。</p>
<p>通过查看代码，要注意两点：</p>
<ul>
<li>[ ] 两个input field的名字是firstname和last name， 这两个名字是我们一会儿要POST到server去的。</li>
<li>[ ] 这里处理form的文件是processing.php，也是我们一会要传送的。</li>
</ul>
<p>怎么在爬虫中完成登录，在这里介绍python的Request library，非常简单的代码：</p>
<p>`import requests</p>
<p>params = {‘firstname’: ‘Ryan’, ‘lastname’: ‘Mitchell’}<br>r = requests.post(“<a href="http://pythonscraping.com/files/processing.php" target="_blank" rel="external">http://pythonscraping.com/files/processing.php</a>“, data = params)<br>print(r.text)`</p>
<p>当然，这里的例子用的form很简单，但是当面对登录页面复杂的HTML代码时，我们也不用过于紧张，我们只需要寻找两类：</p>
<ul>
<li>[ ] 想要提交的数据的field的名字, 比如上面例子的firstname和lastname。</li>
<li>[ ] 真正处理form的action page。</li>
</ul>
<h3 id="爬虫中遇到的Radio-Buttons-Checkboxes和其他输入"><a href="#爬虫中遇到的Radio-Buttons-Checkboxes和其他输入" class="headerlink" title="爬虫中遇到的Radio Buttons, Checkboxes和其他输入"></a>爬虫中遇到的Radio Buttons, Checkboxes和其他输入</h3><p>标准HTML文件包含了很多可能的form input fields，比如radio buttons, checkboxes, select boxes, 在 HTML5中，还有emails, dates等等，尽管登录页面代码看着很复杂，但我们要集中查找以上谈过的两类：</p>
<ul>
<li>[ ] 想要提交的数据的field的名字, 比如上面例子的firstname和lastname。</li>
<li>[ ] 真正处理form的action page。</li>
</ul>
<p>有一种非常便捷的方法查看GET REQUESTS， 就是查看这个site的url，举例说明：假设url长这样<a href="">http: //domainname.com?thing1=foo&amp;thing2=bar</a>。</p>
<h3 id="上传文件和图片"><a href="#上传文件和图片" class="headerlink" title="上传文件和图片"></a>上传文件和图片</h3><p>举例说明操作吧，<a href="https://www.pythonscraping.com/files/form2.html，" target="_blank" rel="external">https://www.pythonscraping.com/files/form2.html，</a> 查看其source code后，我们发现和第一个例子的source code很像，不同点在于这里的<input> type是file，代码如下：</p>
<p>`import requests</p>
<p>files = {‘uploadFile’: open(‘.,/files/pic.png’, ‘rb’)}<br>r =requests(“<a href="https://www.pythonscraping.com/pages/processing2.php" target="_blank" rel="external">https://www.pythonscraping.com/pages/processing2.php</a>“, files=files)<br>print(r.text)`</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/06/21/爬虫中遇到的登录login和form/" data-id="cjjmy51sa000m2alvbj9um7gu" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/">leetcode</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/推荐系统/">推荐系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/深度学习/">深度学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/leetcode/" style="font-size: 20px;">leetcode</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/推荐系统/" style="font-size: 10px;">推荐系统</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a> <a href="/tags/爬虫/" style="font-size: 20px;">爬虫</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">June 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/07/15/Recsys-Spotify-2018-Challenge/">Recsys-Spotify-2018-Challenge比赛总结</a>
          </li>
        
          <li>
            <a href="/2017/11/13/Word2Vec/">Word2Vec模型</a>
          </li>
        
          <li>
            <a href="/2017/11/09/python_script_function/">一些python function总结</a>
          </li>
        
          <li>
            <a href="/2017/11/04/kaggle_dog_breed_idnentification/">kaggle dog breed identification基于Tensorflow迁移学习搭建图片分类器</a>
          </li>
        
          <li>
            <a href="/2017/06/26/一些在爬虫中用到的python tricks/">爬虫笔记4</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Bowen He<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>